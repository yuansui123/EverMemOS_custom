"""
Pipeline Ê†∏ÂøÉ

ËØÑÊµãÊµÅÁ®ãÁöÑÁºñÊéíÂô®ÔºåË¥üË¥£ÂçèË∞É Add ‚Üí Search ‚Üí Answer ‚Üí Evaluate Âõõ‰∏™Èò∂ÊÆµ„ÄÇ
"""
import time
from pathlib import Path
from typing import List, Dict, Any, Optional

from evaluation.src.core.data_models import (
    Dataset, SearchResult, AnswerResult, EvaluationResult
)
from evaluation.src.adapters.base import BaseAdapter
from evaluation.src.evaluators.base import BaseEvaluator
from evaluation.src.utils.logger import setup_logger, get_console
from evaluation.src.utils.saver import ResultSaver
from evaluation.src.utils.checkpoint import CheckpointManager

# ÂØºÂÖ•Á≠îÊ°àÁîüÊàêÊâÄÈúÄÁöÑÁªÑ‰ª∂
from memory_layer.llm.llm_provider import LLMProvider

# ÂØºÂÖ•ÂêÑ‰∏™Èò∂ÊÆµÁöÑÊâßË°åÂáΩÊï∞
from evaluation.src.core.stages.add_stage import run_add_stage
from evaluation.src.core.stages.search_stage import run_search_stage
from evaluation.src.core.stages.answer_stage import run_answer_stage
from evaluation.src.core.stages.evaluate_stage import run_evaluate_stage


class Pipeline:
    """
    ËØÑÊµã Pipeline
    
    ÂõõÈò∂ÊÆµÊµÅÁ®ãÔºö
    1. Add: ÊëÑÂÖ•ÂØπËØùÊï∞ÊçÆÂπ∂ÊûÑÂª∫Á¥¢Âºï
    2. Search: Ê£ÄÁ¥¢Áõ∏ÂÖ≥ËÆ∞ÂøÜ
    3. Answer: ÁîüÊàêÁ≠îÊ°à
    4. Evaluate: ËØÑ‰º∞Á≠îÊ°àË¥®Èáè
    """
    
    def __init__(
        self,
        adapter: BaseAdapter,
        evaluator: BaseEvaluator,
        llm_provider: LLMProvider,
        output_dir: Path,
        run_name: str = "default",
        use_checkpoint: bool = True,
        filter_categories: Optional[List[int]] = None,
    ):
        """
        ÂàùÂßãÂåñ Pipeline
        
        Args:
            adapter: Á≥ªÁªüÈÄÇÈÖçÂô®
            evaluator: ËØÑ‰º∞Âô®
            llm_provider: LLM ProviderÔºàÁî®‰∫éÁ≠îÊ°àÁîüÊàêÔºâ
            output_dir: ËæìÂá∫ÁõÆÂΩï
            run_name: ËøêË°åÂêçÁß∞ÔºàÁî®‰∫éÂå∫ÂàÜ‰∏çÂêåËøêË°åÔºâ
            use_checkpoint: ÊòØÂê¶ÂêØÁî®Êñ≠ÁÇπÁª≠‰º†
            filter_categories: ÈúÄË¶ÅËøáÊª§ÊéâÁöÑÈóÆÈ¢òÁ±ªÂà´ÂàóË°®ÔºàÂ¶Ç [5] Ë°®Á§∫ËøáÊª§Êéâ Category 5Ôºâ
        """
        self.adapter = adapter
        self.evaluator = evaluator
        self.llm_provider = llm_provider
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger = setup_logger(self.output_dir / "pipeline.log")
        self.saver = ResultSaver(self.output_dir)
        self.console = get_console()
        
        # Êñ≠ÁÇπÁª≠‰º†ÊîØÊåÅ
        self.use_checkpoint = use_checkpoint
        self.checkpoint = CheckpointManager(output_dir=output_dir, run_name=run_name) if use_checkpoint else None
        self.completed_stages: set = set()
        
        # ÈóÆÈ¢òÁ±ªÂà´ËøáÊª§ÈÖçÁΩÆÔºà‰ªéÊï∞ÊçÆÈõÜÈÖçÁΩÆ‰∏≠ËØªÂèñÔºâ
        self.filter_categories = filter_categories or []
    
    async def run(
        self,
        dataset: Dataset,
        stages: Optional[List[str]] = None,
        smoke_test: bool = False,
        smoke_messages: int = 10,
        smoke_questions: int = 3,
    ) -> Dict[str, Any]:
        """
        ËøêË°åÂÆåÊï¥ Pipeline
        
        Args:
            dataset: Ê†áÂáÜÊ†ºÂºèÊï∞ÊçÆÈõÜ
            stages: Ë¶ÅÊâßË°åÁöÑÈò∂ÊÆµÂàóË°®ÔºåNone Ë°®Á§∫ÂÖ®ÈÉ®
                   ÂèØÈÄâÂÄº: ["add", "search", "answer", "evaluate"]
            smoke_test: ÊòØÂê¶‰∏∫ÂÜíÁÉüÊµãËØï
            smoke_messages: ÂÜíÁÉüÊµãËØïÊó∂ÁöÑÊ∂àÊÅØÊï∞ÈáèÔºàÈªòËÆ§10Ôºâ
            smoke_questions: ÂÜíÁÉüÊµãËØïÊó∂ÁöÑÈóÆÈ¢òÊï∞ÈáèÔºàÈªòËÆ§3Ôºâ
            
        Returns:
            ËØÑÊµãÁªìÊûúÂ≠óÂÖ∏
        """
        start_time = time.time()
        
        self.console.print(f"\n{'='*60}", style="bold cyan")
        self.console.print("üöÄ Evaluation Pipeline", style="bold cyan")
        self.console.print(f"{'='*60}", style="bold cyan")
        self.console.print(f"Dataset: {dataset.dataset_name}")
        self.console.print(f"System: {self.adapter.get_system_info()['name']}")
        self.console.print(f"Stages: {stages or 'all'}")
        if smoke_test:
            self.console.print(f"[yellow]üß™ Smoke Test Mode: {smoke_messages} messages, {smoke_questions} questions[/yellow]")
        self.console.print(f"{'='*60}\n", style="bold cyan")
        
        # ÂÜíÁÉüÊµãËØïÔºöÂè™Â§ÑÁêÜÁ¨¨‰∏Ä‰∏™ÂØπËØùÁöÑÂâç K Êù°Ê∂àÊÅØÂíåÂâç K ‰∏™ÈóÆÈ¢ò
        if smoke_test:
            dataset = self._apply_smoke_test(dataset, smoke_messages, smoke_questions)
            self.console.print(f"[yellow]‚úÇÔ∏è  Smoke test applied:[/yellow]")
            self.console.print(f"[yellow]   - Conversation: {dataset.conversations[0].conversation_id}[/yellow]")
            self.console.print(f"[yellow]   - Messages: {len(dataset.conversations[0].messages)}[/yellow]")
            self.console.print(f"[yellow]   - Questions: {len(dataset.qa_pairs)}[/yellow]\n")
        
        # Ê†πÊçÆÈÖçÁΩÆËøáÊª§ÈóÆÈ¢òÁ±ªÂà´ÔºàÂ¶ÇËøáÊª§Êéâ Category 5 ÂØπÊäóÊÄßÈóÆÈ¢òÔºâ
        original_qa_count = len(dataset.qa_pairs)
        
        if self.filter_categories:
            # Â∞ÜÈÖçÁΩÆ‰∏≠ÁöÑÁ±ªÂà´Áªü‰∏ÄËΩ¨‰∏∫Â≠óÁ¨¶‰∏≤ÔºàÂÖºÂÆπ int Âíå str ÈÖçÁΩÆÔºâ
            filter_set = {str(cat) for cat in self.filter_categories}
            
            # ËøáÊª§ÊéâÊåáÂÆöÁ±ªÂà´ÁöÑÈóÆÈ¢ò
            dataset.qa_pairs = [
                qa for qa in dataset.qa_pairs 
                if qa.category not in filter_set
            ]
            
            filtered_count = original_qa_count - len(dataset.qa_pairs)
            
            if filtered_count > 0:
                filtered_categories_str = ", ".join(sorted(filter_set))
                self.console.print(
                    f"[dim]üîç Filtered out {filtered_count} questions from categories: {filtered_categories_str}[/dim]"
                )
                self.console.print(f"[dim]   Remaining questions: {len(dataset.qa_pairs)}[/dim]\n")
        
        # Â∞ùËØïÂä†ËΩΩ checkpoint
        search_results_data = None
        answer_results_data = None
        
        if self.use_checkpoint and self.checkpoint:
            checkpoint_data = self.checkpoint.load_checkpoint()
            if checkpoint_data:
                self.completed_stages = set(checkpoint_data.get('completed_stages', []))
                # Âä†ËΩΩÂ∑≤‰øùÂ≠òÁöÑ‰∏≠Èó¥ÁªìÊûú
                if 'search_results' in checkpoint_data:
                    search_results_data = checkpoint_data['search_results']
                if 'answer_results' in checkpoint_data:
                    answer_results_data = checkpoint_data['answer_results']
        
        # ÈªòËÆ§ÊâßË°åÊâÄÊúâÈò∂ÊÆµ
        if stages is None:
            stages = ["add", "search", "answer", "evaluate"]
        
        results = {}
        
        # ===== Stage 1: Add =====
        add_just_completed = False  # üî• Ê†áËÆ∞ add ÊòØÂê¶ÂàöÂàöÂÆåÊàê
        
        if "add" in stages and "add" not in self.completed_stages:
            self.logger.info("Starting Stage 1: Add")
            
            # üî• ÂáÜÂ§áÈò∂ÊÆµÔºöÊ∏ÖÁêÜÂ∑≤ÊúâÊï∞ÊçÆÔºàÂ¶ÇÊûúÈúÄË¶ÅÔºâ
            # try:
            #     await self.adapter.prepare(conversations=dataset.conversations)
            # except Exception as e:
            #     self.logger.warning(f"Preparation stage failed: {e}")
            #     self.console.print(f"\n[yellow]‚ö†Ô∏è  Preparation failed: {e}[/yellow]")
            #     self.console.print("[yellow]   Continuing with Add stage...[/yellow]")
            
            stage_results = await run_add_stage(
                adapter=self.adapter,
                dataset=dataset,
                output_dir=self.output_dir,
                checkpoint_manager=self.checkpoint,
                logger=self.logger,
                console=self.console,
                completed_stages=self.completed_stages,
            )
            results.update(stage_results)
            add_just_completed = True  # üî• Add ÂàöÂàöÂÆåÊàê
            
        elif "add" in self.completed_stages:
            self.console.print("\n[yellow]‚è≠Ô∏è  Skip Add stage (already completed)[/yellow]")
            # üî• ÈáçÊñ∞ÊûÑÂª∫Á¥¢ÂºïÂÖÉÊï∞ÊçÆÔºàÁî± adapter Ë¥üË¥£Ôºå‰ªÖÊú¨Âú∞Á≥ªÁªüÈúÄË¶ÅÔºâ
            # ÂØπ‰∫éÂú®Á∫ø APIÔºåËøîÂõû NoneÔºå‰ΩÜ‰ªçÈúÄËÆæÁΩÆ results["index"]
            index = self.adapter.build_lazy_index(dataset.conversations, self.output_dir)
            results["index"] = index  # Âç≥‰ΩøÊòØ None ‰πüË¶ÅËÆæÁΩÆ
        else:
            # üî• ÈáçÊñ∞ÊûÑÂª∫Á¥¢ÂºïÂÖÉÊï∞ÊçÆÔºàÁî± adapter Ë¥üË¥£Ôºå‰ªÖÊú¨Âú∞Á≥ªÁªüÈúÄË¶ÅÔºâ
            # ÂØπ‰∫éÂú®Á∫ø APIÔºåËøîÂõû NoneÔºå‰ΩÜ‰ªçÈúÄËÆæÁΩÆ results["index"]
            index = self.adapter.build_lazy_index(dataset.conversations, self.output_dir)
            results["index"] = index  # Âç≥‰ΩøÊòØ None ‰πüË¶ÅËÆæÁΩÆ
            if index is not None:
                self.logger.info("‚è≠Ô∏è  Skipped Stage 1, using lazy loading")
        
        # ‚è∞ Post-Add Wait: ÂØπ‰∫éÂú®Á∫ø API Á≥ªÁªüÔºåÁ≠âÂæÖÂêéÂè∞Á¥¢ÂºïÊûÑÂª∫ÂÆåÊàê
        # üî• ÂÖ≥ÈîÆ‰øÆÂ§çÔºöÂè™ÊúâÂΩì add ÂàöÂàöÂÆåÊàêÊó∂ÊâçÁ≠âÂæÖ
        if add_just_completed:
            wait_seconds = self.adapter.config.get("post_add_wait_seconds", 0)
            if wait_seconds > 0 and "search" in stages:
                self.console.print(
                    f"\n[yellow]‚è∞ Waiting {wait_seconds}s for backend indexing to complete...[/yellow]"
                )
                self.logger.info(f"‚è∞ Waiting {wait_seconds}s for backend indexing")
                
                # ÊòæÁ§∫ÂÄíËÆ°Êó∂ËøõÂ∫¶Êù°
                from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeRemainingColumn
                with Progress(
                    SpinnerColumn(),
                    TextColumn("[progress.description]{task.description}"),
                    BarColumn(),
                    TextColumn("{task.percentage:>3.0f}%"),
                    TimeRemainingColumn(),
                    console=self.console
                ) as progress:
                    task = progress.add_task(
                        f"‚è∞ Backend indexing in progress...",
                        total=wait_seconds
                    )
                    for i in range(wait_seconds):
                        time.sleep(1)
                        progress.update(task, advance=1)
                
                self.console.print(f"[green]‚úÖ Wait completed, ready for search[/green]\n")
                self.logger.info("‚úÖ Post-add wait completed")
        
        # ===== Stage 2: Search =====
        if "search" in stages and "search" not in self.completed_stages:
            self.logger.info("Starting Stage 2: Search")
            
            search_results = await run_search_stage(
                adapter=self.adapter,
                qa_pairs=dataset.qa_pairs,
                index=results["index"],
                conversations=dataset.conversations,  # ‰º†ÈÄí conversations Áî®‰∫éÈáçÂª∫ÁºìÂ≠ò
                checkpoint_manager=self.checkpoint,
                logger=self.logger,
            )
            
            self.saver.save_json(
                [self._search_result_to_dict(sr) for sr in search_results],
                "search_results.json"
            )
            results["search_results"] = search_results
            self.logger.info("‚úÖ Stage 2 completed")
            
            # ‰øùÂ≠ò checkpoint
            self.completed_stages.add("search")
            if self.checkpoint:
                search_results_data = [self._search_result_to_dict(sr) for sr in search_results]
                self.checkpoint.save_checkpoint(
                    self.completed_stages,
                    search_results=search_results_data
                )
        elif "search" in self.completed_stages:
            self.console.print(f"\n[yellow]‚è≠Ô∏è  Skip Search stage (already completed)[/yellow]")
            if search_results_data:
                # ‰ªé checkpoint Âä†ËΩΩ
                search_results = [self._dict_to_search_result(d) for d in search_results_data]
                results["search_results"] = search_results
            elif self.saver.file_exists("search_results.json"):
                # ‰ªéÊñá‰ª∂Âä†ËΩΩ
                search_data = self.saver.load_json("search_results.json")
                search_results = [self._dict_to_search_result(d) for d in search_data]
                results["search_results"] = search_results
        elif "answer" in stages or "eval" in stages:
            # Âè™ÊúâÂΩìÂêéÁª≠Èò∂ÊÆµÈúÄË¶Å search_results Êó∂ÔºåÊâçÂ∞ùËØïÂä†ËΩΩ
            if self.saver.file_exists("search_results.json"):
                search_data = self.saver.load_json("search_results.json")
                search_results = [self._dict_to_search_result(d) for d in search_data]
                results["search_results"] = search_results
                self.logger.info("‚è≠Ô∏è  Skipped Stage 2, loaded existing results")
            else:
                raise FileNotFoundError("Search results not found. Please run 'search' stage first.")
        else:
            # ‰∏çÈúÄË¶Å search_resultsÔºà‰æãÂ¶ÇÂè™ËøêË°å add Èò∂ÊÆµÔºâ
            search_results = None
        
        # ===== Stage 3: Answer =====
        if "answer" in stages and "answer" not in self.completed_stages:
            self.logger.info("Starting Stage 3: Answer")
            
            answer_results = await run_answer_stage(
                adapter=self.adapter,
                qa_pairs=dataset.qa_pairs,
                search_results=search_results,
                checkpoint_manager=self.checkpoint,
                logger=self.logger,
            )
            
            self.saver.save_json(
                [self._answer_result_to_dict(ar) for ar in answer_results],
                "answer_results.json"
            )
            results["answer_results"] = answer_results
            self.logger.info("‚úÖ Stage 3 completed")
            
            # ‰øùÂ≠ò checkpoint
            self.completed_stages.add("answer")
            if self.checkpoint:
                answer_results_dict = [self._answer_result_to_dict(ar) for ar in answer_results]
                self.checkpoint.save_checkpoint(
                    self.completed_stages,
                    search_results=search_results_data if search_results_data else [self._search_result_to_dict(sr) for sr in search_results],
                    answer_results=answer_results_dict
                )
        elif "answer" in self.completed_stages:
            self.console.print(f"\n[yellow]‚è≠Ô∏è  Skip Answer stage (already completed)[/yellow]")
            if answer_results_data:
                # ‰ªé checkpoint Âä†ËΩΩ
                answer_results = [self._dict_to_answer_result(d) for d in answer_results_data]
                results["answer_results"] = answer_results
            elif self.saver.file_exists("answer_results.json"):
                # ‰ªéÊñá‰ª∂Âä†ËΩΩ
                answer_data = self.saver.load_json("answer_results.json")
                answer_results = [self._dict_to_answer_result(d) for d in answer_data]
                results["answer_results"] = answer_results
        elif "evaluate" in stages:
            # Âè™ÊúâÂΩì evaluate Èò∂ÊÆµÈúÄË¶Å answer_results Êó∂ÔºåÊâçÂ∞ùËØïÂä†ËΩΩ
            if self.saver.file_exists("answer_results.json"):
                answer_data = self.saver.load_json("answer_results.json")
                answer_results = [self._dict_to_answer_result(d) for d in answer_data]
                results["answer_results"] = answer_results
                self.logger.info("‚è≠Ô∏è  Skipped Stage 3, loaded existing results")
            else:
                raise FileNotFoundError("Answer results not found. Please run 'answer' stage first.")
        else:
            # ‰∏çÈúÄË¶Å answer_resultsÔºà‰æãÂ¶ÇÂè™ËøêË°å add Êàñ searchÔºâ
            answer_results = None
        
        # ===== Stage 4: Evaluate =====
        if "evaluate" in stages and "evaluate" not in self.completed_stages:
            eval_result = await run_evaluate_stage(
                evaluator=self.evaluator,
                answer_results=answer_results,
                checkpoint_manager=self.checkpoint,
                logger=self.logger,
            )
            
            self.saver.save_json(
                self._eval_result_to_dict(eval_result),
                "eval_results.json"
            )
            results["eval_result"] = eval_result
            
            # ‰øùÂ≠ò checkpoint
            self.completed_stages.add("evaluate")
            if self.checkpoint:
                self.checkpoint.save_checkpoint(
                    self.completed_stages,
                    search_results=search_results_data if search_results_data else [self._search_result_to_dict(sr) for sr in search_results],
                    answer_results=answer_results_data if answer_results_data else [self._answer_result_to_dict(ar) for ar in answer_results],
                    eval_results=self._eval_result_to_dict(eval_result)
                )
        elif "evaluate" in self.completed_stages:
            self.console.print("\n[yellow]‚è≠Ô∏è  Skip Evaluate stage (already completed)[/yellow]")
        
        # ÁîüÊàêÊä•Âëä
        elapsed_time = time.time() - start_time
        self._generate_report(results, elapsed_time)
        
        return results
    
    def _apply_smoke_test(
        self, 
        dataset: Dataset, 
        num_messages: int, 
        num_questions: int
    ) -> Dataset:
        """
        Â∫îÁî®ÂÜíÁÉüÊµãËØïÔºöÂè™‰øùÁïôÁ¨¨‰∏Ä‰∏™ÂØπËØùÁöÑÂâç N Êù°Ê∂àÊÅØÂíåÂâç M ‰∏™ÈóÆÈ¢ò
        
        ËøôÊ†∑ÂèØ‰ª•Âø´ÈÄüÈ™åËØÅÂÆåÊï¥ÊµÅÁ®ãÔºàAdd ‚Üí Search ‚Üí Answer ‚Üí EvaluateÔºâÔºå
        ‰ΩÜÂè™‰ΩøÁî®Â∞ëÈáèÊï∞ÊçÆÔºåËäÇÁúÅÊó∂Èó¥„ÄÇ
        
        Args:
            dataset: ÂéüÂßãÊï∞ÊçÆÈõÜ
            num_messages: ‰øùÁïôÁöÑÊ∂àÊÅØÊï∞ÈáèÔºàÁî®‰∫é Add Èò∂ÊÆµÔºâÔºå0 Ë°®Á§∫ÊâÄÊúâÊ∂àÊÅØ
            num_questions: ‰øùÁïôÁöÑÈóÆÈ¢òÊï∞ÈáèÔºàÁî®‰∫é Search/Answer/Evaluate Èò∂ÊÆµÔºâÔºå0 Ë°®Á§∫ÊâÄÊúâÈóÆÈ¢ò
            
        Returns:
            Ë£ÅÂâ™ÂêéÁöÑÊï∞ÊçÆÈõÜ
        """
        if not dataset.conversations:
            return dataset
        
        # Âè™‰øùÁïôÁ¨¨‰∏Ä‰∏™ÂØπËØù
        first_conv = dataset.conversations[0]
        conv_id = first_conv.conversation_id
        
        # Êà™ÂèñÂâç N Êù°Ê∂àÊÅØÔºàÁî®‰∫é AddÔºâ
        # 0 Ë°®Á§∫‰øùÁïôÊâÄÊúâÊ∂àÊÅØ
        if num_messages > 0:
            total_messages = len(first_conv.messages)
            first_conv.messages = first_conv.messages[:num_messages]
            msg_desc = f"{len(first_conv.messages)}/{total_messages}"
        else:
            msg_desc = f"{len(first_conv.messages)} (all)"
        
        # 0 Ë°®Á§∫‰øùÁïôÊâÄÊúâÈóÆÈ¢ò
        conv_qa_pairs = [
            qa for qa in dataset.qa_pairs 
            if qa.metadata.get("conversation_id") == conv_id
        ]
        if num_questions > 0:
            total_questions = len(conv_qa_pairs)
            selected_qa_pairs = conv_qa_pairs[:num_questions]
            qa_desc = f"{len(selected_qa_pairs)}/{total_questions}"
        else:
            selected_qa_pairs = conv_qa_pairs
            qa_desc = f"{len(selected_qa_pairs)} (all)"
        
        self.logger.info(
            f"Smoke test: Conv {conv_id} - "
            f"{msg_desc} messages, "
            f"{qa_desc} questions"
        )
        
        return Dataset(
            dataset_name=dataset.dataset_name + "_smoke",
            conversations=[first_conv],
            qa_pairs=selected_qa_pairs,
            metadata={
                **dataset.metadata, 
                "smoke_test": True, 
                "smoke_messages": num_messages if num_messages > 0 else len(first_conv.messages),
                "smoke_questions": num_questions if num_questions > 0 else len(selected_qa_pairs),
            }
        )
    
    def _generate_report(self, results: Dict[str, Any], elapsed_time: float):
        """ÁîüÊàêËØÑÊµãÊä•Âëä"""
        report_lines = []
        report_lines.append("=" * 60)
        report_lines.append("üìä Evaluation Report")
        report_lines.append("=" * 60)
        report_lines.append("")
        
        # Á≥ªÁªü‰ø°ÊÅØ
        system_info = self.adapter.get_system_info()
        report_lines.append(f"System: {system_info['name']}")
        report_lines.append(f"Time Elapsed: {elapsed_time:.2f}s")
        report_lines.append("")
        
        # ËØÑ‰º∞ÁªìÊûú
        if "eval_result" in results:
            eval_result = results["eval_result"]
            report_lines.append(f"Total Questions: {eval_result.total_questions}")
            report_lines.append(f"Correct: {eval_result.correct}")
            report_lines.append(f"Accuracy: {eval_result.accuracy:.2%}")
            report_lines.append("")
        
        report_lines.append("=" * 60)
        
        report_text = "\n".join(report_lines)
        
        # ‰øùÂ≠òÊä•Âëä
        report_path = self.output_dir / "report.txt"
        with open(report_path, "w") as f:
            f.write(report_text)
        
        # ÊâìÂç∞Âà∞ÊéßÂà∂Âè∞
        self.console.print("\n" + report_text, style="bold green")
        self.logger.info(f"Report saved to: {report_path}")
    
    # Â∫èÂàóÂåñËæÖÂä©ÊñπÊ≥ï
    def _search_result_to_dict(self, sr: SearchResult) -> dict:
        """Â∞Ü SearchResult ÂØπË±°ËΩ¨Êç¢‰∏∫Â≠óÂÖ∏"""
        return {
            "query": sr.query,
            "conversation_id": sr.conversation_id,
            "results": sr.results,
            "retrieval_metadata": sr.retrieval_metadata,
        }
    
    def _dict_to_search_result(self, d: dict) -> SearchResult:
        """Â∞ÜÂ≠óÂÖ∏ËΩ¨Êç¢‰∏∫ SearchResult ÂØπË±°"""
        return SearchResult(**d)
    
    def _answer_result_to_dict(self, ar: AnswerResult) -> dict:
        """Â∞Ü AnswerResult ÂØπË±°ËΩ¨Êç¢‰∏∫Â≠óÂÖ∏"""
        # Â§ÑÁêÜÁ©∫ÁöÑ search_results
        search_results = ar.search_results
        if search_results:
            # Ê£ÄÊü•ÊòØÂê¶ÊâÄÊúâÁªìÊûúÁöÑ content ÈÉΩ‰∏∫Á©∫
            all_empty = all(
                not result.get("content", "").strip() 
                for result in search_results
            )
            if all_empty:
                search_results = []
        
        return {
            "question_id": ar.question_id,
            "question": ar.question,
            "answer": ar.answer,
            "golden_answer": ar.golden_answer,
            "category": ar.category,
            "conversation_id": ar.conversation_id,
            "search_results": search_results,
            "metadata": ar.metadata,
        }
    
    def _dict_to_answer_result(self, d: dict) -> AnswerResult:
        """Â∞ÜÂ≠óÂÖ∏ËΩ¨Êç¢‰∏∫ AnswerResult ÂØπË±°"""
        return AnswerResult(**d)
    
    def _eval_result_to_dict(self, er: EvaluationResult) -> dict:
        """Â∞Ü EvaluationResult ÂØπË±°ËΩ¨Êç¢‰∏∫Â≠óÂÖ∏"""
        return {
            "total_questions": er.total_questions,
            "correct": er.correct,
            "accuracy": er.accuracy,
            "detailed_results": er.detailed_results,
            "metadata": er.metadata,
        }
