"""
æ•°æ®åŠ è½½å™¨

æä¾›ä¸åŒæ•°æ®é›†çš„åŠ è½½åŠŸèƒ½ã€‚
æ”¯æŒè‡ªåŠ¨è½¬æ¢é Locomo æ ¼å¼çš„æ•°æ®é›†ã€‚
"""
import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Optional

from evaluation.src.core.data_models import Dataset, Conversation, Message, QAPair
from evaluation.src.converters.registry import get_converter


def load_dataset(dataset_name: str, data_path: str) -> Dataset:
    """
    æ™ºèƒ½åŠ è½½æ•°æ®é›†ï¼ˆæ”¯æŒè‡ªåŠ¨è½¬æ¢ï¼‰
    
    Args:
        dataset_name: æ•°æ®é›†åç§°ï¼ˆå¦‚ "locomo", "longmemeval", "personamem"ï¼‰
        data_path: æ•°æ®æ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„
        
    Returns:
        Dataset: æ ‡å‡†æ ¼å¼æ•°æ®é›†
    """
    data_path_obj = Path(data_path)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢
    converter = get_converter(dataset_name)
    
    if converter:
        # éœ€è¦è½¬æ¢çš„æ•°æ®é›†
        if data_path_obj.is_file():
            # å¦‚æœç»™çš„æ˜¯æ–‡ä»¶è·¯å¾„ï¼Œå–å…¶çˆ¶ç›®å½•
            data_dir = data_path_obj.parent
        else:
            data_dir = data_path_obj
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢
        if converter.needs_conversion(data_dir):
            print(f"ğŸ“ Converted file not found, converting {dataset_name}...")
            
            # æ„å»ºè¾“å…¥æ–‡ä»¶è·¯å¾„
            input_files = converter.get_input_files()
            input_paths = {
                key: str(data_dir / filename)
                for key, filename in input_files.items()
            }
            
            # æ‰§è¡Œè½¬æ¢
            output_path = str(converter.get_converted_path(data_dir))
            converter.convert(input_paths, output_path)
        
        # ä½¿ç”¨ converted æ–‡ä»¶
        locomo_file = converter.get_converted_path(data_dir)
    else:
        # åŸç”Ÿ Locomo æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
        if data_path_obj.is_file():
            locomo_file = data_path_obj
        else:
            # å¦‚æœæ˜¯ç›®å½•ï¼Œå°è¯•æ‰¾åˆ° .json æ–‡ä»¶
            json_files = list(data_path_obj.glob("*.json"))
            if not json_files:
                raise FileNotFoundError(f"No JSON file found in {data_path_obj}")
            locomo_file = json_files[0]
    
    return load_locomo_dataset(str(locomo_file), dataset_name=dataset_name)


def load_locomo_dataset(data_path: str, dataset_name: str = "locomo") -> Dataset:
    """
    åŠ è½½ LoCoMo æ ¼å¼çš„æ•°æ®é›†
    
    Args:
        data_path: Locomo æ ¼å¼æ•°æ®æ–‡ä»¶è·¯å¾„
        dataset_name: æ•°æ®é›†åç§°ï¼ˆé»˜è®¤ä¸º "locomo"ï¼Œè½¬æ¢åçš„æ•°æ®é›†åº”ä¼ å…¥åŸå§‹åç§°ï¼‰
        
    Returns:
        Dataset: æ ‡å‡†æ ¼å¼æ•°æ®é›†
    """
    with open(data_path, "r", encoding="utf-8") as f:
        raw_data = json.load(f)
    
    conversations = []
    qa_pairs = []
    
    for idx, item in enumerate(raw_data):
        # ğŸ”¥ æ·»åŠ æ•°æ®é›†å‰ç¼€ï¼Œé¿å…ä¸åŒæ•°æ®é›†é—´çš„ conversation_id å†²çª
        # ä¾‹å¦‚ï¼šlocomo_0, longmemeval_0, personamem_0
        conv_id = f"{dataset_name}_{idx}"
        conversation_data = item.get("conversation", {})
        qa_data = item.get("qa", [])
        
        # è½¬æ¢å¯¹è¯
        conversation = _convert_locomo_conversation(conversation_data, conv_id)
        conversations.append(conversation)
        
        # è½¬æ¢ QA å¯¹
        for qa_idx, qa_item in enumerate(qa_data):
            qa_pair = _convert_locomo_qa_pair(qa_item, conv_id, qa_idx)
            qa_pairs.append(qa_pair)
    
    return Dataset(
        dataset_name=dataset_name,
        conversations=conversations,
        qa_pairs=qa_pairs,
        metadata={"total_conversations": len(conversations)}
    )


def _convert_locomo_conversation(conversation_data: dict, conv_id: str) -> Conversation:
    """è½¬æ¢ LoCoMo å¯¹è¯"""
    messages = []
    
    # è·å–æ‰€æœ‰ session keys
    session_keys = sorted([
        key for key in conversation_data.keys()
        if key.startswith("session_") and not key.endswith("_date_time")
    ])
    
    # ğŸ”¥ ä¸ºæ²¡æœ‰æ—¶é—´æˆ³çš„æ•°æ®ç”Ÿæˆä¼ªé€ çš„èµ·å§‹æ—¶é—´ï¼ˆç”¨äº online APIï¼‰
    # ä½¿ç”¨ä¸€ä¸ªå›ºå®šçš„åŸºå‡†æ—¶é—´ï¼š2024-01-01 00:00:00
    fake_base_time = datetime(2024, 1, 1, 0, 0, 0)
    
    # ğŸ”¥ ç¬¬ä¸€æ­¥ï¼šè§£ææ‰€æœ‰ session çš„æ—¶é—´æˆ³
    session_times = []
    for session_idx, session_key in enumerate(session_keys):
        session_time_key = f"{session_key}_date_time"
        if session_time_key in conversation_data:
            session_time = _parse_locomo_timestamp(conversation_data[session_time_key])
            
            # å¦‚æœè§£æå¤±è´¥æˆ–ä¸º "Unknown"ï¼Œç”Ÿæˆä¼ªé€ æ—¶é—´æˆ³
            is_fake = (session_time is None)
            if is_fake:
                session_time = fake_base_time + timedelta(hours=session_idx)
            
            session_times.append({
                "time": session_time,
                "is_fake": is_fake
            })
        else:
            # æ²¡æœ‰ date_time å­—æ®µï¼Œç”Ÿæˆä¼ªé€ æ—¶é—´æˆ³
            session_times.append({
                "time": fake_base_time + timedelta(hours=session_idx),
                "is_fake": True
            })
    
    # ğŸ”¥ ç¬¬äºŒæ­¥ï¼šä¸ºæ¯ä¸ª session åˆ†é…æ¶ˆæ¯æ—¶é—´æˆ³
    for session_idx, session_key in enumerate(session_keys):
        session_messages = conversation_data[session_key]
        
        if not session_messages:
            continue
        
        # è·å–å½“å‰ session çš„èµ·å§‹æ—¶é—´
        current_session_time = session_times[session_idx]["time"]
        is_fake_timestamp = session_times[session_idx]["is_fake"]
        
        # ğŸ”¥ è®¡ç®—æ¶ˆæ¯æ—¶é—´é—´éš”
        # ç­–ç•¥ï¼šä¼˜å…ˆä½¿ç”¨30ç§’é—´éš”ï¼Œåªæœ‰åœ¨ä¼šè¶…å‡ºä¸‹ä¸€ä¸ªsessionæ—¶æ‰ç¼©å°é—´éš”
        num_messages = len(session_messages)
        default_interval = 30  # é»˜è®¤30ç§’é—´éš”
        
        if num_messages > 1:
            # è®¡ç®—ä½¿ç”¨é»˜è®¤é—´éš”éœ€è¦çš„æ€»æ—¶é•¿
            required_duration = (num_messages - 1) * default_interval
            
            # è·å–å¯ç”¨çš„æ—¶é—´è·¨åº¦
            if session_idx + 1 < len(session_times):
                # æœ‰ä¸‹ä¸€ä¸ª sessionï¼šè®¡ç®—åˆ°ä¸‹ä¸€ä¸ª session çš„æ—¶é—´
                next_session_time = session_times[session_idx + 1]["time"]
                available_duration = (next_session_time - current_session_time).total_seconds()
                
                # å¦‚æœæ—¶é—´è·¨åº¦ä¸ºè´Ÿæˆ–å¤ªå°ï¼ˆè¯´æ˜æ•°æ®æœ‰é—®é¢˜ï¼‰ï¼Œä½¿ç”¨é»˜è®¤é—´éš”
                if available_duration <= 0:
                    time_interval = default_interval
                # ç•™å‡º10%ç¼“å†²ï¼Œé¿å…æœ€åä¸€æ¡æ¶ˆæ¯å¤ªæ¥è¿‘ä¸‹ä¸€ä¸ª session
                elif required_duration > available_duration * 0.9:
                    # éœ€è¦ç¼©å°é—´éš”æ‰èƒ½æ”¾ä¸‹æ‰€æœ‰æ¶ˆæ¯
                    time_interval = (available_duration * 0.9) / (num_messages - 1)
                else:
                    # å¯ä»¥ä½¿ç”¨é»˜è®¤é—´éš”
                    time_interval = default_interval
            else:
                # æœ€åä¸€ä¸ª sessionï¼šç›´æ¥ä½¿ç”¨é»˜è®¤é—´éš”
                time_interval = default_interval
        else:
            # åªæœ‰ä¸€æ¡æ¶ˆæ¯ï¼Œæ”¾åœ¨ session å¼€å§‹æ—¶
            time_interval = 0
        
        # è½¬æ¢æ¯æ¡æ¶ˆæ¯
        for msg_idx, msg in enumerate(session_messages):
            msg_timestamp = current_session_time + timedelta(seconds=msg_idx * time_interval)
            
            message = Message(
                speaker_id=f"{msg['speaker'].lower().replace(' ', '_')}_{conv_id}",
                speaker_name=msg['speaker'],
                content=msg['text'],
                timestamp=msg_timestamp,
                metadata={
                    "session": session_key,
                    "dia_id": msg.get("dia_id"),
                    "img_url": msg.get("img_url"),
                    "blip_caption": msg.get("blip_caption"),
                    "is_fake_timestamp": is_fake_timestamp,  # æ ‡è®°æ˜¯å¦ä¸ºä¼ªé€ æ—¶é—´æˆ³
                }
            )
            messages.append(message)
    
    return Conversation(
        conversation_id=conv_id,
        messages=messages,
        metadata={
            "speaker_a": conversation_data.get("speaker_a"),
            "speaker_b": conversation_data.get("speaker_b"),
        }
    )


def _convert_locomo_qa_pair(qa_item: dict, conv_id: str, qa_idx: int) -> QAPair:
    """è½¬æ¢ LoCoMo QA å¯¹"""
    # æå–é¢å¤–çš„å­—æ®µåˆ° metadata
    metadata = {"conversation_id": conv_id}
    
    # å¦‚æœæœ‰ all_optionsï¼ˆPersonaMem é€‰æ‹©é¢˜ï¼‰ï¼Œä¿å­˜åˆ° metadata
    if "all_options" in qa_item:
        metadata["all_options"] = qa_item["all_options"]
    
    # ä¼˜å…ˆä½¿ç”¨æ•°æ®ä¸­çš„ question_idï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦åˆ™ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„ ID
    question_id = qa_item.get("question_id")
    if not question_id:
        # ä½¿ç”¨ conv_id + qa_idx ç”Ÿæˆå”¯ä¸€ IDï¼Œç¡®ä¿ä¸ä¼šå†²çª
        question_id = f"{conv_id}_qa{qa_idx}"
    
    # ç»Ÿä¸€å°† category è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆå…¼å®¹ int å’Œ strï¼‰
    category = qa_item.get("category")
    if category is not None:
        category = str(category)
    
    return QAPair(
        question_id=question_id,
        question=qa_item.get("question", ""),
        answer=qa_item.get("answer", ""),
        category=category,
        evidence=qa_item.get("evidence", []),
        metadata=metadata
    )


def _parse_locomo_timestamp(timestamp_str: str) -> Optional[datetime]:
    """
    è§£æ LoCoMo çš„æ—¶é—´æ ¼å¼
    
    è¾“å…¥æ ¼å¼: "6:07 pm on 13 January, 2023"
    ç‰¹æ®Šå€¼: "Unknown" æˆ–æ— æ³•è§£ææ—¶è¿”å› None
    è¾“å‡º: datetime å¯¹è±¡æˆ– None
    """
    # æ¸…ç†å­—ç¬¦ä¸²
    timestamp_str = timestamp_str.replace("\\s+", " ").strip()
    
    # å¤„ç†ç‰¹æ®Šæƒ…å†µï¼šUnknown æˆ–ç©ºå­—ç¬¦ä¸²
    if timestamp_str.lower() == "unknown" or not timestamp_str:
        # æ²¡æœ‰æ—¶é—´ä¿¡æ¯ï¼Œè¿”å› None
        return None
    
    try:
        return datetime.strptime(timestamp_str, "%I:%M %p on %d %B, %Y")
    except ValueError:
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å› None å¹¶è¾“å‡ºè­¦å‘Š
        print(f"âš ï¸  Warning: Failed to parse timestamp '{timestamp_str}', no timestamp will be set")
        return None

