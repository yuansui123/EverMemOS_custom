# Memos System Configuration

name: "memos"
version: "1.0"
description: "Memos"

adapter: "memos"

# Memos API configuration
api_url: "https://memos.memtensor.cn/api/openmem/v1"
api_key: "${MEMOS_KEY}"
batch_size: 10  # Number of messages to send per batch (default)
max_retries: 5

# Rate limiting (Memos has 10 requests/second limit)
request_interval: 0.1  # Seconds to wait after each API call (10 req/s = 0.1s)

# Concurrency configuration
num_workers: 1  # Process conversations sequentially due to rate limit

# Dataset-specific overrides
# Configuration overrides for specific datasets
dataset_overrides:
  longmemeval:
    batch_size: 6  # LongMemEval has large data, use smaller batch_size

# ‚è∞ Post-Add Wait: Wait for background index build to complete (if needed)
# Online API systems are usually asynchronous, so it takes time to build the index
post_add_wait_seconds: 180  # Wait 180 seconds before starting search


# LLM configuration (for answer generation)
llm:
  provider: "openai"
  model: "openai/gpt-4.1-mini"
  api_key: "${LLM_API_KEY}"
  base_url: "${LLM_BASE_URL:https://openrouter.ai/api/v1}"
  temperature: 0
  max_tokens: 32768

# Search configuration
search:
  top_k: 20

# Answer configuration
answer:
  max_retries: 3

