# Metrics Library Design

## ğŸ¯ Design Goals

1. **Business isolation from third-party dependencies**: Business code only references its own metrics library, no direct dependency on `prometheus_client`
2. **Lightweight auto-refresh**: Each Gauge instance manages its own refresh task, no global scheduler needed
3. **Unified inheritance pattern**: All Gauges inherit from BaseGauge and override the refresh method
4. **Unified interface**: Counter, Histogram, and Gauge use consistent wrappers

---

## ğŸ“ Core Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              src/core/metrics/ (wrapper layer)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   Counter   â”‚  â”‚  Histogram  â”‚  â”‚  BaseGauge  â”‚         â”‚
â”‚  â”‚  (wrapper)  â”‚  â”‚  (wrapper)  â”‚  â”‚(wrapper+ref)â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â”‚                â”‚                  â”‚                â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                          â”‚                                   â”‚
â”‚                 wraps prometheus_client                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†‘ imports
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Business code (only imports core.metrics)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  from core.metrics import Counter, Histogram, BaseGauge     â”‚
â”‚                                                               â”‚
â”‚  # Unified inheritance pattern                               â”‚
â”‚  class QueueSizeGauge(BaseGauge):                           â”‚
â”‚      def __init__(self, queue):                             â”‚
â”‚          super().__init__('queue_size', 'Queue size')       â”‚
â”‚          self.queue = queue                                 â”‚
â”‚                                                               â”‚
â”‚      def refresh(self, labels: dict) -> float:              â”‚
â”‚          return self.queue.qsize()                          â”‚
â”‚                                                               â”‚
â”‚  # Usage                                                     â”‚
â”‚  gauge = QueueSizeGauge(queue)                              â”‚
â”‚  gauge.labels(name='main').start_refresh()  # default 5 sec â”‚
â”‚  # or manual set                                             â”‚
â”‚  gauge.labels(name='main').set(42)                          â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’» Core Implementation

### 1. Counter Wrapper

**File: `src/core/metrics/counter.py`**

```python
"""
Counter Wrapper

Provides a unified Counter interface, isolating prometheus_client
"""
from prometheus_client import Counter as PrometheusCounter
from typing import Sequence
from .registry import get_metrics_registry


class Counter:
    """
    Counter metric wrapper

    Features:
    - Monotonically increasing counter
    - Suitable for total requests, total errors, etc.
    - Business code doesn't need to import prometheus_client directly

    Usage example:
        from core.metrics import Counter

        requests_total = Counter(
            name='http_requests_total',
            description='Total HTTP requests',
            labelnames=['method', 'path', 'status']
        )

        # Usage
        requests_total.labels(method='GET', path='/api', status='200').inc()
    """

    def __init__(
        self,
        name: str,
        description: str,
        labelnames: Sequence[str] = (),
        namespace: str = '',
        subsystem: str = '',
        unit: str = '',
    ):
        """
        Args:
            name: Metric name
            description: Metric description
            labelnames: List of label names
            namespace: Namespace (optional)
            subsystem: Subsystem (optional)
            unit: Unit (optional)
        """
        registry = get_metrics_registry()
        
        self._counter = PrometheusCounter(
            name=name,
            documentation=description,
            labelnames=labelnames,
            namespace=namespace,
            subsystem=subsystem,
            unit=unit,
            registry=registry,
        )
    
    def labels(self, **labels):
        """
        Return a labeled Counter

        Returns:
            LabeledCounter instance
        """
        labeled = self._counter.labels(**labels)
        return LabeledCounter(labeled)
    
    def inc(self, amount: float = 1) -> None:
        """
        Increment counter (unlabeled version)

        Args:
            amount: Increment amount, default 1
        """
        self._counter.inc(amount)


class LabeledCounter:
    """Labeled Counter"""

    def __init__(self, labeled_counter):
        self._counter = labeled_counter

    def inc(self, amount: float = 1) -> None:
        """
        Increment counter

        Args:
            amount: Increment amount, default 1
        """
        self._counter.inc(amount)
```

---

### 2. Histogram Wrapper

**File: `src/core/metrics/histogram.py`**

```python
"""
Histogram Wrapper

Provides a unified Histogram interface, isolating prometheus_client
"""
from prometheus_client import Histogram as PrometheusHistogram
from typing import Sequence
from .registry import get_metrics_registry


class Histogram:
    """
    Histogram metric wrapper

    Features:
    - Distribution statistics of observed values
    - Suitable for latency, size, and other distribution data
    - Automatically calculates quantiles, mean, and sum

    Usage example:
        from core.metrics import Histogram
        
        request_duration = Histogram(
            name='http_request_duration_seconds',
            description='HTTP request duration',
            labelnames=['method', 'path'],
            buckets=(0.01, 0.05, 0.1, 0.5, 1.0, 5.0)
        )
        
        # Usage
        request_duration.labels(method='GET', path='/api').observe(0.123)
    """

    def __init__(
        self,
        name: str,
        description: str,
        labelnames: Sequence[str] = (),
        namespace: str = '',
        subsystem: str = '',
        unit: str = '',
        buckets: Sequence[float] = (
            0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5,
            0.75, 1.0, 2.5, 5.0, 7.5, 10.0
        ),
    ):
        """
        Args:
            name: Metric name
            description: Metric description
            labelnames: List of label names
            namespace: Namespace (optional)
            subsystem: Subsystem (optional)
            unit: Unit (optional)
            buckets: Histogram bucket boundaries
        """
        registry = get_metrics_registry()
        
        self._histogram = PrometheusHistogram(
            name=name,
            documentation=description,
            labelnames=labelnames,
            namespace=namespace,
            subsystem=subsystem,
            unit=unit,
            buckets=buckets,
            registry=registry,
        )
    
    def labels(self, **labels):
        """
        Return a labeled Histogram

        Returns:
            LabeledHistogram instance
        """
        labeled = self._histogram.labels(**labels)
        return LabeledHistogram(labeled)
    
    def observe(self, amount: float) -> None:
        """
        Record an observation (unlabeled version)

        Args:
            amount: Observed value
        """
        self._histogram.observe(amount)


class LabeledHistogram:
    """Labeled Histogram"""

    def __init__(self, labeled_histogram):
        self._histogram = labeled_histogram

    def observe(self, amount: float) -> None:
        """
        Record an observation

        Args:
            amount: Observed value
        """
        self._histogram.observe(amount)
```

---

### 3. BaseGauge Base Class (Core)

**File: `src/core/metrics/gauge.py`**

```python
"""
Gauge Wrapper

Provides a unified Gauge interface with built-in auto-refresh capability
"""
from prometheus_client import Gauge as PrometheusGauge
from typing import Sequence, Optional, Callable, Any
import asyncio
import logging
from abc import ABC

logger = logging.getLogger(__name__)


class BaseGauge(ABC):
    """
    Gauge base class

    Features:
    - Instant value that can increase or decrease
    - Built-in auto-refresh capability (default 5 seconds)
    - Must inherit and override refresh() method
    - Each instance manages its own refresh task
    - Supports manual set() method

    Usage - inherit and override refresh method:
        class KafkaPendingMessagesGauge(BaseGauge):
            def __init__(self, kafka_consumer):
                super().__init__(
                    name='kafka_pending_messages',
                    description='Number of pending messages',
                    labelnames=['job_name']
                )
                self.kafka_consumer = kafka_consumer
            
            def refresh(self, labels: dict) -> float:
                '''Return current value'''
                return len(self.kafka_consumer.pending_messages)

        # Usage 1: Auto-refresh (default 5 seconds)
        gauge = KafkaPendingMessagesGauge(kafka_consumer)
        gauge.labels(job_name='tanka').start_refresh()

        # Usage 2: Custom refresh interval
        gauge.labels(job_name='tanka').start_refresh(interval_seconds=10)

        # Usage 3: Manual set (no auto-refresh)
        gauge.labels(job_name='tanka').set(42)
    """

    def __init__(
        self,
        name: str,
        description: str,
        labelnames: Sequence[str] = (),
        namespace: str = '',
        subsystem: str = '',
        unit: str = '',
    ):
        """
        Args:
            name: Metric name
            description: Metric description
            labelnames: List of label names
            namespace: Namespace (optional)
            subsystem: Subsystem (optional)
            unit: Unit (optional)
        """
        from .registry import get_metrics_registry
        registry = get_metrics_registry()
        
        self._gauge = PrometheusGauge(
            name=name,
            documentation=description,
            labelnames=labelnames,
            namespace=namespace,
            subsystem=subsystem,
            unit=unit,
            registry=registry,
        )
        
        self._name = name
        self._labelnames = labelnames
        
        # Store refresh task for each label combination
        # key: label å€¼çš„ tuple, value: RefreshTask
        self._refresh_tasks: dict[tuple, 'RefreshTask'] = {}
    
    def labels(self, **labels) -> 'LabeledGauge':
        """
        Return a labeled Gauge
        
        Returns:
            LabeledGauge å®ä¾‹
        """
        labeled_gauge = self._gauge.labels(**labels)
        label_key = self._make_label_key(**labels)
        
        return LabeledGauge(
            base_gauge=self,
            labeled_gauge=labeled_gauge,
            label_key=label_key,
            label_dict=labels,
        )
    
    def set(self, value: float) -> None:
        """Set value (unlabeled version)"""
        self._gauge.set(value)
    
    def inc(self, amount: float = 1) -> None:
        """Increment value (unlabeled version)"""
        self._gauge.inc(amount)
    
    def dec(self, amount: float = 1) -> None:
        """Decrement value (unlabeled version)"""
        self._gauge.dec(amount)
    
    def refresh(self, labels: dict) -> float:
        """
        åˆ·æ–°æ–¹æ³•ï¼ˆå­ç±»å¿…é¡»é‡å†™ï¼‰
        
        Args:
            labels: æ ‡ç­¾å­—å…¸
        
        Returns:
            å½“å‰ Gauge å€¼
        
        è¯´æ˜ï¼š
            - å­ç±»å¿…é¡»é‡å†™æ­¤æ–¹æ³•æ¥å®ç°è‡ªå®šä¹‰åˆ·æ–°é€»è¾‘
            - æ­¤æ–¹æ³•ä¼šè¢«è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡å®šæœŸè°ƒç”¨ï¼ˆé»˜è®¤ 5 ç§’ï¼‰
            - å¯ä»¥è¿”å›ä»»ä½• float å€¼ï¼Œä¼šè‡ªåŠ¨æ›´æ–°åˆ° Gauge
        
        ç¤ºä¾‹ï¼š
            class QueueSizeGauge(BaseGauge):
                def __init__(self, queue):
                    super().__init__('queue_size', 'Queue size')
                    self.queue = queue
                
                def refresh(self, labels: dict) -> float:
                    return self.queue.qsize()
        """
        raise NotImplementedError(
            f"Gauge '{self._name}' must override refresh() method"
        )
    
    def _make_label_key(self, **labels) -> tuple:
        """Generate label key"""
        if self._labelnames:
            return tuple(labels.get(name, '') for name in self._labelnames)
        return ()
    
    async def _stop_all_refresh_tasks(self) -> None:
        """Stop all refresh tasks"""
        for task in self._refresh_tasks.values():
            await task.stop()
        self._refresh_tasks.clear()


class LabeledGauge:
    """
    å¸¦æ ‡ç­¾çš„ Gauge
    
    æä¾›å’ŒåŸç”Ÿ Gauge ä¸€è‡´çš„æ¥å£ï¼ŒåŒæ—¶æ”¯æŒè‡ªåŠ¨åˆ·æ–°
    """
    
    def __init__(
        self,
        base_gauge: BaseGauge,
        labeled_gauge: Any,
        label_key: tuple,
        label_dict: dict,
    ):
        self._base_gauge = base_gauge
        self._labeled_gauge = labeled_gauge
        self._label_key = label_key
        self._label_dict = label_dict
    
    def set(self, value: float) -> None:
        """Set value"""
        self._labeled_gauge.set(value)
    
    def inc(self, amount: float = 1) -> None:
        """Increment value"""
        self._labeled_gauge.inc(amount)
    
    def dec(self, amount: float = 1) -> None:
        """Decrement value"""
        self._labeled_gauge.dec(amount)
    
    def set_to_current_time(self) -> None:
        """Set to current timestamp"""
        self._labeled_gauge.set_to_current_time()
    
    def start_refresh(
        self,
        interval_seconds: int = 5,
        enable_async: bool = True,
    ) -> 'LabeledGauge':
        """
        å¯åŠ¨è‡ªåŠ¨åˆ·æ–°
        
        Args:
            interval_seconds: åˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 5 ç§’
            enable_async: æ˜¯å¦æ”¯æŒå¼‚æ­¥ refresh æ–¹æ³•ï¼Œé»˜è®¤ True
        
        Returns:
            selfï¼ˆæ”¯æŒé“¾å¼è°ƒç”¨ï¼‰
        
        ç¤ºä¾‹ï¼š
            # default 5 second refresh
            gauge.labels(job='tanka').start_refresh()
            
            # è‡ªå®šä¹‰åˆ·æ–°é—´éš”
            gauge.labels(job='tanka').start_refresh(interval_seconds=10)
            
            # å¼‚æ­¥ refresh æ–¹æ³•
            class AsyncGauge(BaseGauge):
                async def refresh(self, labels: dict) -> float:
                    return await self.get_value_async()
            
            gauge.labels(type='A').start_refresh(enable_async=True)
        """
        # åˆ›å»ºåŒ…è£…å‡½æ•°ï¼Œè°ƒç”¨ base_gauge.refresh()
        def refresh_wrapper():
            return self._base_gauge.refresh(self._label_dict)
        
        # åˆ›å»ºåˆ·æ–°ä»»åŠ¡
        task = RefreshTask(
            refresh_func=refresh_wrapper,
            labeled_gauge=self._labeled_gauge,
            interval_seconds=interval_seconds,
            enable_async=enable_async,
            label_key=self._label_key,
        )
        
        # å­˜å‚¨ä»»åŠ¡
        self._base_gauge._refresh_tasks[self._label_key] = task
        
        # å¯åŠ¨ä»»åŠ¡
        task.start()
        
        return self
    
    async def stop_refresh(self) -> None:
        """Stop auto-refresh"""
        task = self._base_gauge._refresh_tasks.get(self._label_key)
        if task:
            await task.stop()
            del self._base_gauge._refresh_tasks[self._label_key]


class RefreshTask:
    """
    åˆ·æ–°ä»»åŠ¡
    
    æ¯ä¸ªæ ‡ç­¾ç»„åˆä¸€ä¸ªç‹¬ç«‹çš„åˆ·æ–°ä»»åŠ¡
    """
    
    def __init__(
        self,
        refresh_func: Callable[[], float],
        labeled_gauge: Any,
        interval_seconds: int,
        enable_async: bool,
        label_key: tuple,
    ):
        self.refresh_func = refresh_func
        self.labeled_gauge = labeled_gauge
        self.interval_seconds = interval_seconds
        self.enable_async = enable_async
        self.label_key = label_key
        
        self._task: Optional[asyncio.Task] = None
        self._running = False
        self._error_count = 0
    
    def start(self) -> None:
        """Start refresh task"""
        if self._running:
            logger.warning(f"Refresh task already running for {self.label_key}")
            return
        
        self._running = True
        self._task = asyncio.create_task(self._refresh_loop())
        logger.info(
            f"Started refresh task: label_key={self.label_key}, "
            f"interval={self.interval_seconds}s"
        )
    
    async def stop(self) -> None:
        """Stop refresh task"""
        if not self._running:
            return
        
        self._running = False
        
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
            self._task = None
        
        logger.info(f"Stopped refresh task: label_key={self.label_key}")
    
    async def _refresh_loop(self) -> None:
        """Refresh loop"""
        while self._running:
            try:
                # Call refresh function
                if self.enable_async and asyncio.iscoroutinefunction(self.refresh_func):
                    value = await self.refresh_func()
                else:
                    value = self.refresh_func()
                
                # Update Gauge
                self.labeled_gauge.set(value)
                
                # Reset error count
                self._error_count = 0
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self._error_count += 1
                logger.error(
                    f"Refresh failed for {self.label_key}: {e} "
                    f"(error_count={self._error_count})",
                    exc_info=True
                )
            
            # Wait for next refresh
            try:
                await asyncio.sleep(self.interval_seconds)
            except asyncio.CancelledError:
                break
```

---

### 4. Unified Export

**File:`src/core/metrics/__init__.py`**

```python
"""
Metrics Library

Business code imports metric classes from here, no direct dependency on prometheus_client needed

ä½¿ç”¨ç¤ºä¾‹ï¼š
    from core.metrics import Counter, Histogram, BaseGauge
    
    # Counter
    requests_total = Counter('http_requests_total', 'Total requests', ['method'])
    requests_total.labels(method='GET').inc()
    
    # Histogram
    request_duration = Histogram('http_request_duration_seconds', 'Request duration', ['method'])
    request_duration.labels(method='GET').observe(0.123)
    
    # Gauge - inheritance pattern
    class QueueSizeGauge(BaseGauge):
        def __init__(self, queue):
            super().__init__('queue_size', 'Queue size', ['queue_name'])
            self.queue = queue
        
        def refresh(self, labels: dict) -> float:
            return self.queue.qsize()
    
    # Using Gauge
    gauge = QueueSizeGauge(queue)
    gauge.labels(queue_name='main').start_refresh()  # default 5 second refresh
    # or manual set
    gauge.labels(queue_name='main').set(42)
"""

from .counter import Counter
from .histogram import Histogram
from .gauge import BaseGauge
from .registry import get_metrics_registry, generate_metrics_response

__all__ = [
    'Counter',
    'Histogram',
    'BaseGauge',
    'get_metrics_registry',
    'generate_metrics_response',
]
```

---

## ğŸ’¡ Usage Examples

### Example 1: Kafka Metrics

**File:`src/infra_layer/adapters/input/mq/metrics/kafka_metrics.py`**

```python
"""
Kafka metrics definition

Only imports core.metrics, no direct prometheus_client import
"""
from core.metrics import Counter, Histogram, BaseGauge


# ============================================================
# Counter and Histogram - direct usage
# ============================================================

KAFKA_PROCESSED_MESSAGES_TOTAL = Counter(
    name='kafka_processed_messages_total',
    description='Total number of processed Kafka messages',
    labelnames=['job_name', 'status'],
)

KAFKA_MESSAGE_PROCESSING_DURATION = Histogram(
    name='kafka_message_processing_duration_seconds',
    description='Duration of message processing',
    labelnames=['job_name'],
    buckets=(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 2.5, 5.0, 10.0),
)


# ============================================================
# Gauge - unified inheritance pattern
# ============================================================

class KafkaPendingMessagesGauge(BaseGauge):
    """Kafka pending messages Gauge"""
    
    def __init__(self, kafka_consumer):
        super().__init__(
            name='kafka_prefill_pending_messages',
            description='Number of pending messages in prefill stage',
            labelnames=['job_name'],
        )
        self.kafka_consumer = kafka_consumer
    
    def refresh(self, labels: dict) -> float:
        """Return current pending message count"""
        return len(self.kafka_consumer.prefill_pending_messages)


class KafkaActiveConsumersGauge(BaseGauge):
    """Kafka active consumers Gauge"""
    
    def __init__(self, kafka_consumer):
        super().__init__(
            name='kafka_active_consumers',
            description='Number of active consumer tasks',
            labelnames=['job_name'],
        )
        self.kafka_consumer = kafka_consumer
    
    def refresh(self, labels: dict) -> float:
        """Return current active consumer count"""
        return len(self.kafka_consumer.consumer_tasks)


class KafkaRedisQueueSizeGauge(BaseGauge):
    """Redis queue size Gauge"""
    
    def __init__(self, redis_queue_manager):
        super().__init__(
            name='kafka_redis_queue_size',
            description='Total size of Redis queues',
            labelnames=['job_name'],
        )
        self.redis_queue_manager = redis_queue_manager
    
    def refresh(self, labels: dict) -> float:
        """Return total Redis queue size"""
        if not self.redis_queue_manager:
            return 0
        
        total_size = 0
        for partition in self.redis_queue_manager.partitions.values():
            size = partition.size()
            total_size += size
        
        return total_size


class KafkaMemoryQueueSizeGauge(BaseGauge):
    """Memory queue size Gauge"""
    
    def __init__(self, memory_queue_manager):
        super().__init__(
            name='kafka_memory_queue_size',
            description='Total size of in-memory queues',
            labelnames=['job_name'],
        )
        self.memory_queue_manager = memory_queue_manager
    
    def refresh(self, labels: dict) -> float:
        """Return total memory queue size"""
        if not self.memory_queue_manager:
            return 0
        
        return sum(
            q.qsize() 
            for q in self.memory_queue_manager._queues.values()
        )
```

### Example 2: Business Code Usage

**File:`src/infra_layer/adapters/input/mq/tanka_kafka_consumer.py`**

```python
"""
Kafka consumer - using wrapped metrics library
"""
import time
from .metrics.kafka_metrics import (
    KAFKA_PROCESSED_MESSAGES_TOTAL,
    KAFKA_MESSAGE_PROCESSING_DURATION,
    KafkaPendingMessagesGauge,
    KafkaActiveConsumersGauge,
    KafkaRedisQueueSizeGauge,
    KafkaMemoryQueueSizeGauge,
)


class TankaKafkaConsumer:
    """Kafka consumer"""
    
    def __init__(
        self,
        job_id: str,
        redis_queue_manager=None,
        memory_queue_manager=None,
        **kwargs
    ):
        self.job_id = job_id
        self.redis_queue_manager = redis_queue_manager
        self.memory_queue_manager = memory_queue_manager
        
        # Business properties
        self.prefill_pending_messages = []
        self.consumer_tasks = []
        
        # ... other initialization ...
        
        # âœ… Set up Gauge auto-refresh
        self._setup_metrics()
    
    def _setup_metrics(self) -> None:
        """Set up metric auto-refresh"""
        
        # 1. Pending message countï¼ˆdefault 5 second refreshï¼‰
        pending_gauge = KafkaPendingMessagesGauge(self)
        pending_gauge.labels(
            job_name=self.job_id
        ).start_refresh()  # é»˜è®¤ 5 ç§’
        
        # 2. Active consumer countï¼ˆdefault 5 second refreshï¼‰
        active_gauge = KafkaActiveConsumersGauge(self)
        active_gauge.labels(
            job_name=self.job_id
        ).start_refresh()
        
        # 3. Redis é˜Ÿåˆ—å¤§å°ï¼ˆè‡ªå®šä¹‰ 10 ç§’åˆ·æ–°ï¼‰
        if self.redis_queue_manager:
            redis_gauge = KafkaRedisQueueSizeGauge(self.redis_queue_manager)
            redis_gauge.labels(
                job_name=self.job_id
            ).start_refresh(interval_seconds=10)
        
        # 4. å†…å­˜é˜Ÿåˆ—å¤§å°ï¼ˆdefault 5 second refreshï¼‰
        if self.memory_queue_manager:
            memory_gauge = KafkaMemoryQueueSizeGauge(self.memory_queue_manager)
            memory_gauge.labels(
                job_name=self.job_id
            ).start_refresh()
    
    async def _process_message(self, message) -> None:
        """å¤„ç†æ¶ˆæ¯"""
        start_time = time.time()
        
        try:
            # Business logic
            await self._do_process(message)
            
            # âœ… Counter
            KAFKA_PROCESSED_MESSAGES_TOTAL.labels(
                job_name=self.job_id,
                status='success'
            ).inc()
            
        except Exception as e:
            # âœ… Counterï¼ˆé”™è¯¯ï¼‰
            KAFKA_PROCESSED_MESSAGES_TOTAL.labels(
                job_name=self.job_id,
                status='error'
            ).inc()
            raise
        
        finally:
            # âœ… Histogram
            duration = time.time() - start_time
            KAFKA_MESSAGE_PROCESSING_DURATION.labels(
                job_name=self.job_id
            ).observe(duration)
```

### ç¤ºä¾‹ 3ï¼šMemory Metrics

**File:`src/agentic_layer/metrics/memory_metrics.py`**

```python
"""
Memory æŒ‡æ ‡å®šä¹‰
"""
from core.metrics import Counter, Histogram, BaseGauge


# Counter å’Œ Histogram
RETRIEVE_REQUESTS_TOTAL = Counter(
    name='memory_retrieve_requests_total',
    description='Total number of memory retrieve requests',
    labelnames=['retrieve_method', 'status'],
)

RETRIEVE_DURATION_SECONDS = Histogram(
    name='memory_retrieve_duration_seconds',
    description='Duration of memory retrieve operations',
    labelnames=['retrieve_method'],
    buckets=(0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0),
)


# Gauge - unified inheritance pattern
class MemoryCacheSizeGauge(BaseGauge):
    """Memory Cache å¤§å° Gauge"""
    
    def __init__(self, service, cache_type: str):
        super().__init__(
            name='memory_cache_size',
            description='Current size of memory cache',
            labelnames=['cache_type'],
        )
        self.service = service
        self.cache_type = cache_type
    
    def refresh(self, labels: dict) -> float:
        """è¿”å›ç¼“å­˜å¤§å°"""
        cache = getattr(self.service, 'cache', {})
        return len(cache)


class MemoryActiveRequestsGauge(BaseGauge):
    """Memory æ´»è·ƒè¯·æ±‚æ•° Gauge"""
    
    def __init__(self, memory_manager, operation: str):
        super().__init__(
            name='memory_active_requests',
            description='Number of active memory requests',
            labelnames=['operation'],
        )
        self.memory_manager = memory_manager
        self.operation = operation
    
    def refresh(self, labels: dict) -> float:
        """è¿”å›æ´»è·ƒè¯·æ±‚æ•°"""
        if self.operation == 'retrieve':
            return getattr(self.memory_manager, 'active_retrieve_count', 0)
        elif self.operation == 'memorize':
            return getattr(self.memory_manager, 'active_memorize_count', 0)
        return 0
```

**File:`src/agentic_layer/memory_manager.py`**

```python
"""
Memory Manager - ä½¿ç”¨ Gauge
"""
from .metrics.memory_metrics import (
    RETRIEVE_REQUESTS_TOTAL,
    RETRIEVE_DURATION_SECONDS,
    MemoryCacheSizeGauge,
    MemoryActiveRequestsGauge,
)


class MemoryManager:
    """Memory Manager"""
    
    def __init__(self, embedding_service, rerank_service):
        self.embedding_service = embedding_service
        self.rerank_service = rerank_service
        self.active_retrieve_count = 0
        self.active_memorize_count = 0
        
        # âœ… Set up Gauge auto-refresh
        self._setup_metrics()
    
    def _setup_metrics(self) -> None:
        """Set up metric auto-refresh"""
        
        # Embedding cache å¤§å°ï¼ˆ10 ç§’åˆ·æ–°ï¼‰
        embedding_cache_gauge = MemoryCacheSizeGauge(
            self.embedding_service, 
            'embedding'
        )
        embedding_cache_gauge.labels(
            cache_type='embedding'
        ).start_refresh(interval_seconds=10)
        
        # Rerank cache å¤§å°ï¼ˆ10 ç§’åˆ·æ–°ï¼‰
        rerank_cache_gauge = MemoryCacheSizeGauge(
            self.rerank_service,
            'rerank'
        )
        rerank_cache_gauge.labels(
            cache_type='rerank'
        ).start_refresh(interval_seconds=10)
        
        # æ´»è·ƒçš„ retrieve è¯·æ±‚ï¼ˆé»˜è®¤ 5 ç§’ï¼‰
        retrieve_gauge = MemoryActiveRequestsGauge(self, 'retrieve')
        retrieve_gauge.labels(
            operation='retrieve'
        ).start_refresh()
        
        # æ´»è·ƒçš„ memorize è¯·æ±‚ï¼ˆé»˜è®¤ 5 ç§’ï¼‰
        memorize_gauge = MemoryActiveRequestsGauge(self, 'memorize')
        memorize_gauge.labels(
            operation='memorize'
        ).start_refresh()
    
    async def retrieve_mem(self, request):
        """æ£€ç´¢è®°å¿†"""
        start_time = time.time()
        retrieve_method = request.retrieve_method
        
        try:
            # Business logic
            memories = await self._do_retrieve(request)
            
            # âœ… Counter
            RETRIEVE_REQUESTS_TOTAL.labels(
                retrieve_method=retrieve_method,
                status='success'
            ).inc()
            
            return memories
        
        finally:
            # âœ… Histogram
            duration = time.time() - start_time
            RETRIEVE_DURATION_SECONDS.labels(
                retrieve_method=retrieve_method
            ).observe(duration)
```

---

## ğŸ¯ æ–¹æ¡ˆä¼˜åŠ¿

1. **ä¸šåŠ¡ä»£ç å®Œå…¨éš”ç¦»ç¬¬ä¸‰æ–¹ä¾èµ–**
   - ä¸šåŠ¡åªå¼•ç”¨ `core.metrics`ï¼Œä¸ç›´æ¥ä¾èµ– `prometheus_client`
   - æ–¹ä¾¿åç»­æ›¿æ¢åº•å±‚å®ç°

2. **ç»Ÿä¸€ç»§æ‰¿æ–¹å¼ï¼Œç®€å•ç›´è§‚**
   - æ‰€æœ‰ Gauge éƒ½ç»§æ‰¿ BaseGauge å¹¶é‡å†™ `refresh()` æ–¹æ³•
   - æ¥å£ç»Ÿä¸€ï¼Œå­¦ä¹ æˆæœ¬ä½
   - ä»£ç é£æ ¼ä¸€è‡´

3. **è½»é‡çº§ï¼Œæ— å…¨å±€è°ƒåº¦å™¨**
   - æ¯ä¸ª Gauge å®ä¾‹è‡ªå·±ç®¡ç†åˆ·æ–°ä»»åŠ¡
   - æ¯ä¸ªæ ‡ç­¾ç»„åˆä¸€ä¸ªç‹¬ç«‹çš„ `asyncio.Task`
   - æ— éœ€å…¨å±€è°ƒåº¦å™¨åè°ƒ

4. **çµæ´»çš„åˆ·æ–°é—´éš”**
   - default 5 second refresh
   - å¯è‡ªå®šä¹‰åˆ·æ–°é—´éš”ï¼ˆ3ç§’ã€10ç§’ã€30ç§’ç­‰ï¼‰
   - ä¸åŒçš„æ ‡ç­¾å¯ä»¥æœ‰ä¸åŒçš„é—´éš”

5. **æ”¯æŒæ‰‹åŠ¨ set()**
   - å¯ä»¥éšæ—¶æ‰‹åŠ¨ `set()` Set value
   - æ‰‹åŠ¨è®¾ç½®å’Œè‡ªåŠ¨åˆ·æ–°äº’ä¸å¹²æ‰°
   - çµæ´»åº”å¯¹å„ç§åœºæ™¯

## ğŸ“Š å¯¹æ¯”æ€»ç»“

| ç»´åº¦ | ç›´æ¥ä½¿ç”¨ prometheus_client | æœ¬æ–¹æ¡ˆ |
|------|--------------------------|--------|
| **ä¾èµ–éš”ç¦»** | ä¸šåŠ¡ä»£ç ç›´æ¥ä¾èµ–ç¬¬ä¸‰æ–¹åº“ | ä¸šåŠ¡ä»£ç åªä¾èµ– core.metrics |
| **Gauge åˆ·æ–°** | æ‰‹åŠ¨è°ƒç”¨ .set() | è‡ªåŠ¨åˆ·æ–°ï¼ˆé»˜è®¤ 5 ç§’ï¼‰ + æ”¯æŒæ‰‹åŠ¨ set() |
| **è°ƒåº¦å™¨** | æ— ï¼ˆæˆ–éœ€è¦è‡ªå·±å®ç°ï¼‰ | æ— éœ€å…¨å±€è°ƒåº¦å™¨ï¼ˆæ¯ä¸ª Gauge ç‹¬ç«‹ï¼‰ |
| **ä½¿ç”¨æ–¹å¼** | éœ€è¦è‡ªå·±å®ç°åˆ·æ–°é€»è¾‘ | ç»§æ‰¿ BaseGauge é‡å†™ refresh() |
| **ä»£ç å¤æ‚åº¦** | ç®€å•ä½†åŠŸèƒ½å°‘ | å°è£…ååŒæ ·ç®€å•ä¸”åŠŸèƒ½æ›´å¤š |
| **å¯æ‰©å±•æ€§** | éœ€è¦è‡ªå·±æ‰©å±• | ç»§æ‰¿ BaseGauge å³å¯æ‰©å±• |

---

## ğŸš€ å®æ–½æ­¥éª¤

### é˜¶æ®µ 1ï¼šåˆ›å»ºå°è£…å±‚
1. âœ… åˆ›å»º `core/metrics/counter.py`
2. âœ… åˆ›å»º `core/metrics/histogram.py`
3. âœ… åˆ›å»º `core/metrics/gauge.py`ï¼ˆæ ¸å¿ƒï¼‰
4. âœ… ä¿®æ”¹ `core/metrics/__init__.py` å¯¼å‡º
5. âœ… ç®€åŒ– `core/metrics/registry.py`ï¼ˆç§»é™¤ MetricsSource/Processorï¼‰

### é˜¶æ®µ 2ï¼šé‡æ„ä¸šåŠ¡æŒ‡æ ‡
1. âœ… é‡æ„ `kafka_metrics.py`ï¼ˆæ”¹ç”¨ core.metricsï¼ŒGauge æ”¹ä¸ºç»§æ‰¿ï¼‰
2. âœ… é‡æ„ `memory_metrics.py`ï¼ˆæ”¹ç”¨ core.metricsï¼ŒGauge æ”¹ä¸ºç»§æ‰¿ï¼‰

### é˜¶æ®µ 3ï¼šä¸šåŠ¡ä»£ç é›†æˆ
1. âœ… ä¿®æ”¹ `TankaKafkaConsumer`ï¼ˆåˆ›å»º Gauge å®ä¾‹å¹¶ start_refreshï¼‰
2. âœ… ä¿®æ”¹ `MemoryManager`ï¼ˆåˆ›å»º Gauge å®ä¾‹å¹¶ start_refreshï¼‰

### é˜¶æ®µ 4ï¼šæ¸…ç†æ—§ä»£ç 
1. âœ… åˆ é™¤æ‰€æœ‰ `*_metrics_processor.py` æ–‡ä»¶
2. âœ… åˆ é™¤æ‰€æœ‰ `*_metrics_source.py` æ–‡ä»¶
3. âœ… åˆ é™¤ `metrics_processor.py` åŸºç±»
4. âœ… åˆ é™¤ `metrics_source.py` åŸºç±»

---

## ğŸ’¡ å…³é”®è®¾è®¡è¦ç‚¹

1. **ç»Ÿä¸€ç»§æ‰¿æ–¹å¼**
   - æ‰€æœ‰ Gauge å¿…é¡»ç»§æ‰¿ BaseGauge
   - å¿…é¡»é‡å†™ `refresh()` æ–¹æ³•
   - ä¸æ”¯æŒ `set_refresher()` æ–¹å¼

2. **default 5 second refresh**
   - `start_refresh()` é»˜è®¤ 5 ç§’é—´éš”
   - å¯é€šè¿‡ `interval_seconds` å‚æ•°è‡ªå®šä¹‰
   - ç¬¦åˆå¤§éƒ¨åˆ†ä¸šåŠ¡åœºæ™¯

3. **æ”¯æŒæ‰‹åŠ¨ set()**
   - å¯ä»¥ä¸å¯åŠ¨è‡ªåŠ¨åˆ·æ–°ï¼Œç›´æ¥æ‰‹åŠ¨ `set()`
   - æ‰‹åŠ¨è®¾ç½®å’Œè‡ªåŠ¨åˆ·æ–°å¯ä»¥æ··ç”¨
   - çµæ´»åº”å¯¹ç‰¹æ®Šåœºæ™¯

4. **è½»é‡çº§å®ç°**
   - RefreshTask ç®¡ç†å•ä¸ªæ ‡ç­¾çš„åˆ·æ–°ä»»åŠ¡
   - æ¯ä¸ªä»»åŠ¡ç‹¬ç«‹çš„ `asyncio.Task`
   - æ— å…¨å±€è°ƒåº¦å™¨ï¼Œæ— æ€§èƒ½å¼€é”€

5. **å¼‚å¸¸éš”ç¦»**
   - æ¯ä¸ª Gauge çš„åˆ·æ–°å¼‚å¸¸ä¸å½±å“å…¶ä»– Gauge
   - è‡ªåŠ¨é”™è¯¯æ—¥å¿—è®°å½•
   - è‡ªåŠ¨é‡è¯•æœºåˆ¶

---

## ğŸ”§ é…ç½®ç¤ºä¾‹

**File:`src/core/config.py`**

```python
from pydantic_settings import BaseSettings


class Settings(BaseSettings):
    # Metrics é…ç½®
    PROMETHEUS_METRICS_ENABLED: bool = True
    
    # Gauge é»˜è®¤åˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰
    # æ³¨æ„ï¼šè¿™æ˜¯å…¨å±€é»˜è®¤å€¼ï¼Œä¸šåŠ¡ä»£ç å¯ä»¥é€šè¿‡ start_refresh(interval_seconds=N) è¦†ç›–
    METRICS_GAUGE_DEFAULT_INTERVAL: int = 5
    
    # ... å…¶ä»–é…ç½® ...


settings = Settings()
```

éœ€è¦æˆ‘å¼€å§‹å®æ–½è¿™ä¸ªæ–¹æ¡ˆå—ï¼Ÿ

