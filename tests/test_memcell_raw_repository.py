#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test the functionality of MemCellRawRepository

Test contents include:
1. CRUD operations based on event_id
2. Queries based on user_id
3. Queries based on time range (including segmented queries)
4. Queries based on group_id
5. Queries based on participants
6. Queries based on keywords
7. Batch deletion operations
8. Statistical and aggregation queries
"""

import asyncio
from common_utils.datetime_utils import get_now_with_timezone
from datetime import timedelta, datetime
from bson import ObjectId
from pydantic import BaseModel, Field

from core.di import get_bean_by_type
from infra_layer.adapters.out.persistence.repository.memcell_raw_repository import (
    MemCellRawRepository,
)
from infra_layer.adapters.out.persistence.document.memory.memcell import (
    MemCell,
    DataTypeEnum,
)
from core.observation.logger import get_logger

logger = get_logger(__name__)


# ==================== Projection Model Definition ====================
class MemCellProjection(BaseModel):
    """
    MemCell projection model - used to test field projection functionality
    Includes only partial fields, excluding large fields such as original_data
    """

    id: ObjectId = Field(alias="_id")
    user_id: str
    timestamp: datetime
    summary: str
    type: DataTypeEnum

    class Config:
        populate_by_name = True
        arbitrary_types_allowed = True


async def test_basic_crud_operations():
    """Test basic CRUD operations based on event_id"""
    logger.info("Starting test of basic CRUD operations based on event_id...")

    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_001"

    try:
        # First clean up any existing test data (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")

        # Test creating a new MemCell
        now = get_now_with_timezone()
        memcell = MemCell(
            user_id=user_id,
            timestamp=now,
            summary="This is a test memory: discussed the project's technical solution",
            type=DataTypeEnum.CONVERSATION,
            keywords=["technical solution", "project discussion"],
            participants=["Zhang San", "Li Si"],
        )

        created = await repo.append_memcell(memcell)
        assert created is not None
        assert created.user_id == user_id
        assert created.summary == "This is a test memory: discussed the project's technical solution"
        assert created.event_id is not None
        logger.info("âœ… Test creating new MemCell succeeded, event_id=%s", created.event_id)

        event_id = str(created.event_id)

        # Test querying by event_id
        queried = await repo.get_by_event_id(event_id)
        assert queried is not None
        assert queried.user_id == user_id
        assert str(queried.event_id) == event_id
        logger.info("âœ… Test querying by event_id succeeded")

        # Test updating MemCell
        update_data = {
            "summary": "Updated summary: project technical solution has been confirmed",
            "keywords": ["technical solution", "project discussion", "confirmed"],
        }

        updated = await repo.update_by_event_id(event_id, update_data)
        assert updated is not None
        assert updated.summary == "Updated summary: project technical solution has been confirmed"
        assert len(updated.keywords) == 3
        logger.info("âœ… Test updating MemCell succeeded")

        # Test deleting MemCell
        deleted = await repo.delete_by_event_id(event_id)
        assert deleted is True
        logger.info("âœ… Test deleting MemCell succeeded")

        # Verify deletion
        final_check = await repo.get_by_event_id(event_id)
        assert final_check is None, "Record should have been deleted"
        logger.info("âœ… Verified deletion succeeded")

    except Exception as e:
        logger.error("âŒ Basic CRUD operations test failed: %s", e)
        raise

    logger.info("âœ… Basic CRUD operations test completed")


async def test_find_by_user_id():
    """Test queries based on user_id"""
    logger.info("Starting test of queries based on user_id...")

    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_002"

    try:
        # First clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")

        # Create multiple records
        now = get_now_with_timezone()
        for i in range(5):
            memcell = MemCell(
                user_id=user_id,
                timestamp=now - timedelta(hours=i),
                summary=f"Test memory {i+1}",
                type=DataTypeEnum.CONVERSATION,
            )
            await repo.append_memcell(memcell)

        logger.info("âœ… Created 5 test records")

        # Test querying all records (descending)
        results = await repo.find_by_user_id(user_id, sort_desc=True)
        assert len(results) == 5
        assert results[0].summary == "Test memory 1"  # Latest
        logger.info("âœ… Test querying all records (descending) succeeded")

        # Test querying all records (ascending)
        results_asc = await repo.find_by_user_id(user_id, sort_desc=False)
        assert len(results_asc) == 5
        assert results_asc[0].summary == "Test memory 5"  # Earliest
        logger.info("âœ… Test querying all records (ascending) succeeded")

        # Test limiting number
        limited_results = await repo.find_by_user_id(user_id, limit=2)
        assert len(limited_results) == 2
        logger.info("âœ… Test limiting number succeeded")

        # Test skip and limit
        skip_results = await repo.find_by_user_id(user_id, skip=2, limit=2)
        assert len(skip_results) == 2
        logger.info("âœ… Test skip and limit succeeded")

        # Clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up test data successfully")

    except Exception as e:
        logger.error("âŒ Test based on user_id query failed: %s", e)
        raise

    logger.info("âœ… Queries based on user_id test completed")


async def test_find_by_time_range():
    """Test queries based on time range (including segmented queries)"""
    logger.info("Starting test of queries based on time range...")

    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_003"

    try:
        # First clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")

        # Create test data with a large span (10 days)
        # Use time from 1990 to avoid conflicts with existing data
        # Note: Must use timezone-aware time, otherwise it will not match the timezone stored in MongoDB
        from common_utils.datetime_utils import get_timezone

        tz = get_timezone()
        start_time = datetime(1990, 1, 1, 0, 0, 0, tzinfo=tz)

        # Create one record per day
        created_timestamps = []
        for i in range(10):
            ts = start_time + timedelta(days=i)
            created_timestamps.append(ts)
            memcell = MemCell(
                user_id=user_id,
                timestamp=ts,
                summary=f"Day {i+1} memory",
                type=DataTypeEnum.CONVERSATION,
            )
            await repo.append_memcell(memcell)

        logger.info("âœ… Created 10 days of test data")
        logger.info(
            "   Timestamp range: %s to %s", created_timestamps[0], created_timestamps[-1]
        )

        # Test small range query (3 days, does not trigger segmentation)
        # Query day 0, 1, 2 (total 3 records)
        small_start = start_time  # 1990-01-01 00:00:00
        small_end = start_time + timedelta(days=3)  # 1990-01-04 00:00:00 (exclusive)
        small_results = await repo.find_by_time_range(small_start, small_end)
        logger.info("   Small range query returned %d records (expected 3)", len(small_results))
        assert (
            len(small_results) == 3
        ), f"Expected 3 records, got {len(small_results)}"
        logger.info("âœ… Test small range query (3 days) succeeded, found %d records", len(small_results))

        # Test large range query (10 days, triggers segmented query)
        # Query day 0-9 (total 10 records)
        # The last record is 1990-01-10 00:00:00, query uses $lt, so end time must be > 1990-01-10
        large_start = start_time  # 1990-01-01 00:00:00
        large_end = start_time + timedelta(
            days=10, seconds=1
        )  # 1990-01-11 00:00:01 (ensure day 9 is included)
        logger.info("   Query time range: %s to %s", large_start, large_end)
        large_results = await repo.find_by_time_range(large_start, large_end)
        logger.info("   Large range query returned %d records (expected 10)", len(large_results))

        # Print returned record timestamps for debugging
        logger.info("   Returned record details:")
        for idx, mc in enumerate(large_results):
            logger.info("     [%d] %s - %s", idx, mc.timestamp, mc.summary)

        if len(large_results) != 10:
            logger.warning("   âš ï¸ Record count mismatch!")
            logger.warning("   Expected timestamps:")
            for idx, ts in enumerate(created_timestamps):
                logger.warning("     [%d] %s", idx, ts)

            # Find missing records
            returned_timestamps = {mc.timestamp for mc in large_results}
            missing = [ts for ts in created_timestamps if ts not in returned_timestamps]
            if missing:
                logger.error("   âŒ Missing timestamps:")
                for ts in missing:
                    logger.error("     - %s", ts)

        assert (
            len(large_results) == 10
        ), f"Expected 10 records, got {len(large_results)}"
        logger.info("âœ… Test large range query (10 days) succeeded, found %d records", len(large_results))

        # Test descending query
        desc_results = await repo.find_by_time_range(
            large_start, large_end, sort_desc=True
        )
        assert len(desc_results) == 10
        assert "Day 10" in desc_results[0].summary  # Latest first
        logger.info("âœ… Test descending query succeeded")

        # Test ascending query
        asc_results = await repo.find_by_time_range(
            large_start, large_end, sort_desc=False
        )
        assert len(asc_results) == 10
        assert "Day 1" in asc_results[0].summary  # Earliest first
        logger.info("âœ… Test ascending query succeeded")

        # Test pagination
        page_results = await repo.find_by_time_range(large_start, large_end, limit=5)
        assert len(page_results) == 5
        logger.info("âœ… Test pagination succeeded")

        # Clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up test data successfully")

    except Exception as e:
        logger.error("âŒ Test time range query failed: %s", e)
        raise

    logger.info("âœ… Time range query test completed")


async def test_find_by_user_and_time_range():
    """Test queries based on user and time range"""
    logger.info("Starting test of queries based on user and time range...")

    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_004"

    try:
        # First clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")

        # Create test data
        now = get_now_with_timezone()
        start_time = now - timedelta(days=5)

        for i in range(5):
            memcell = MemCell(
                user_id=user_id,
                timestamp=start_time + timedelta(days=i),
                summary=f"User memory {i+1}",
                type=DataTypeEnum.CONVERSATION,
            )
            await repo.append_memcell(memcell)

        logger.info("âœ… Created 5 test records")

        # Test querying data for middle 3 days
        query_start = start_time + timedelta(days=1)
        query_end = start_time + timedelta(days=4)
        results = await repo.find_by_user_and_time_range(
            user_id, query_start, query_end
        )

        assert len(results) == 3
        logger.info("âœ… Test user and time range query succeeded, found %d records", len(results))

        # Clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up test data successfully")

    except Exception as e:
        logger.error("âŒ Test user and time range query failed: %s", e)
        raise

    logger.info("âœ… User and time range query test completed")


async def test_find_by_group_id():
    """Test queries based on group_id"""
    logger.info("Starting test of queries based on group_id...")

    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_005"
    group_id = "test_group_001"

    try:
        # First clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")

        # Create group records
        now = get_now_with_timezone()
        for i in range(3):
            memcell = MemCell(
                user_id=user_id,
                group_id=group_id,
                timestamp=now - timedelta(hours=i),
                summary=f"Group memory {i+1}",
                type=DataTypeEnum.CONVERSATION,
            )
            await repo.append_memcell(memcell)

        logger.info("âœ… Created 3 group records")

        # Test query
        results = await repo.find_by_group_id(group_id)
        assert len(results) == 3
        logger.info("âœ… Test querying by group_id succeeded, found %d records", len(results))

        # Clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up test data successfully")

    except Exception as e:
        logger.error("âŒ Test group_id query failed: %s", e)
        raise

    logger.info("âœ… group_id query test completed")


async def test_find_by_participants():
    """Test queries based on participants"""
    logger.info("Starting test of queries based on participants...")

    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_006"

    try:
        # First clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")

        # Create test data
        now = get_now_with_timezone()

        # Record 1: Zhang San, Li Si
        memcell1 = MemCell(
            user_id=user_id,
            timestamp=now - timedelta(hours=1),
            summary="Record 1: Conversation between Zhang San and Li Si",
            participants=["Zhang San", "Li Si"],
        )
        await repo.append_memcell(memcell1)

        # Record 2: Zhang San, Wang Wu
        memcell2 = MemCell(
            user_id=user_id,
            timestamp=now - timedelta(hours=2),
            summary="Record 2: Conversation between Zhang San and Wang Wu",
            participants=["Zhang San", "Wang Wu"],
        )
        await repo.append_memcell(memcell2)

        # Record 3: Li Si, Wang Wu
        memcell3 = MemCell(
            user_id=user_id,
            timestamp=now - timedelta(hours=3),
            summary="Record 3: Conversation between Li Si and Wang Wu",
            participants=["Li Si", "Wang Wu"],
        )
        await repo.append_memcell(memcell3)

        logger.info("âœ… Created 3 test records")

        # Test matching any participant (containing "Zhang San")
        results_any = await repo.find_by_participants(["Zhang San"], match_all=False)
        assert len(results_any) == 2
        logger.info("âœ… Test matching any participant succeeded, found %d records", len(results_any))

        # Test matching all participants (containing both "Zhang San" and "Li Si")
        results_all = await repo.find_by_participants(["Zhang San", "Li Si"], match_all=True)
        assert len(results_all) == 1
        logger.info("âœ… Test matching all participants succeeded, found %d records", len(results_all))

        # Clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up test data successfully")

    except Exception as e:
        logger.error("âŒ Test participant query failed: %s", e)
        raise

    logger.info("âœ… Participant query test completed")


async def test_search_by_keywords():
    """Test queries based on keywords"""
    logger.info("Starting test of queries based on keywords...")

    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_007"

    try:
        # First clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")

        # Create test data
        now = get_now_with_timezone()

        # Record 1: technology, Python
        memcell1 = MemCell(
            user_id=user_id,
            timestamp=now - timedelta(hours=1),
            summary="Record 1: Python technology discussion",
            keywords=["technology", "Python"],
        )
        await repo.append_memcell(memcell1)

        # Record 2: technology, Java
        memcell2 = MemCell(
            user_id=user_id,
            timestamp=now - timedelta(hours=2),
            summary="Record 2: Java technology discussion",
            keywords=["technology", "Java"],
        )
        await repo.append_memcell(memcell2)

        # Record 3: design, architecture
        memcell3 = MemCell(
            user_id=user_id,
            timestamp=now - timedelta(hours=3),
            summary="Record 3: Architecture design discussion",
            keywords=["design", "architecture"],
        )
        await repo.append_memcell(memcell3)

        logger.info("âœ… Created 3 test records")

        # Test matching any keyword (containing "technology")
        results_any = await repo.search_by_keywords(["technology"], match_all=False)
        assert len(results_any) == 2
        logger.info("âœ… Test matching any keyword succeeded, found %d records", len(results_any))

        # Test matching all keywords (containing both "technology" and "Python")
        results_all = await repo.search_by_keywords(["technology", "Python"], match_all=True)
        assert len(results_all) == 1
        logger.info("âœ… Test matching all keywords succeeded, found %d records", len(results_all))

        # Clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up test data successfully")

    except Exception as e:
        logger.error("âŒ Test keyword query failed: %s", e)
        raise

    logger.info("âœ… Keyword query test completed")


async def test_batch_delete_operations():
    """Test batch deletion operations (now soft delete by default)"""
    logger.info("Starting test of batch deletion operations...")

    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_008"

    try:
        # First clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")

        # Create test data
        now = get_now_with_timezone()
        for i in range(10):
            memcell = MemCell(
                user_id=user_id,
                timestamp=now - timedelta(days=i),
                summary=f"Test memory {i+1}",
                type=DataTypeEnum.CONVERSATION,
            )
            await repo.append_memcell(memcell)

        logger.info("âœ… Created 10 test records")

        # Test soft deleting records within a time range (first 5 days)
        delete_start = now - timedelta(days=5)
        delete_end = now
        deleted_count = await repo.delete_by_time_range(
            delete_start, delete_end, user_id=user_id, deleted_by="test"
        )
        assert deleted_count == 5
        logger.info("âœ… Test soft deleting records within time range succeeded, deleted %d records", deleted_count)

        # Verify remaining records (å¸¸è§„æŸ¥è¯¢åªè¿”å›æœªåˆ é™¤çš„)
        remaining = await repo.find_by_user_id(user_id)
        assert len(remaining) == 5
        logger.info("âœ… Verified remaining records successfully, %d records left", len(remaining))

        # Test soft deleting all remaining user records
        total_deleted = await repo.delete_by_user_id(user_id, deleted_by="test")
        assert total_deleted == 5
        logger.info("âœ… Test soft deleting all user records succeeded, deleted %d records", total_deleted)

        # Verify all soft deleted (å¸¸è§„æŸ¥è¯¢æ‰¾ä¸åˆ°)
        final_check = await repo.find_by_user_id(user_id)
        assert len(final_check) == 0
        logger.info("âœ… Verified all soft deleted successfully (not visible in regular queries)")
        
        # Verify using hard_find_many can still find them
        hard_check = await MemCell.hard_find_many({"user_id": user_id}).to_list()
        assert len(hard_check) == 10
        logger.info("âœ… Verified all 10 records still exist (soft deleted)")
        
        # Final cleanup with hard delete
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Hard deleted all records for cleanup")

    except Exception as e:
        logger.error("âŒ Test batch deletion operations failed: %s", e)
        raise

    logger.info("âœ… Batch deletion operations test completed")


async def test_statistics_and_aggregation():
    """Test statistical and aggregation queries"""
    logger.info("Starting test of statistical and aggregation queries...")

    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_009"

    try:
        # First clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")

        # Create test data of different types
        now = get_now_with_timezone()
        start_time = now - timedelta(days=7)

        # Create 6 conversation memories (Note: Originally 3 conversations, 2 emails, 1 document, but now only CONVERSATION type)
        for i in range(3):
            memcell = MemCell(
                user_id=user_id,
                timestamp=start_time + timedelta(days=i),
                summary=f"Conversation memory {i+1}",
                type=DataTypeEnum.CONVERSATION,
            )
            await repo.append_memcell(memcell)

        for i in range(2):
            memcell = MemCell(
                user_id=user_id,
                timestamp=start_time + timedelta(days=i + 3),
                summary=f"Email memory {i+1}",
                type=DataTypeEnum.CONVERSATION,
            )
            await repo.append_memcell(memcell)

        memcell = MemCell(
            user_id=user_id,
            timestamp=start_time + timedelta(days=5),
            summary="Document memory",
            type=DataTypeEnum.CONVERSATION,
        )
        await repo.append_memcell(memcell)

        logger.info("âœ… Created 6 test records (all CONVERSATION type)")

        # Test counting total user records
        total_count = await repo.count_by_user_id(user_id)
        assert total_count == 6
        logger.info("âœ… Test counting total user records succeeded, total %d records", total_count)

        # Test counting records within a time range
        range_start = start_time
        range_end = start_time + timedelta(days=4)
        range_count = await repo.count_by_time_range(
            range_start, range_end, user_id=user_id
        )
        assert range_count == 4  # Records from first 4 days (3 conversation memories + 1 email memory)
        logger.info("âœ… Test counting records within time range succeeded, total %d records", range_count)

        # Test getting user's latest records
        latest = await repo.get_latest_by_user(user_id, limit=3)
        assert len(latest) == 3
        assert latest[0].summary == "Document memory"  # Latest
        logger.info("âœ… Test getting user's latest records succeeded")

        # Clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up test data successfully")

    except Exception as e:
        logger.error("âŒ Test statistical and aggregation queries failed: %s", e)
        raise

    logger.info("âœ… Statistical and aggregation queries test completed")


async def test_get_by_event_ids():
    """Test batch query by event_ids"""
    logger.info("Starting test of batch query by event_ids...")

    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_010"

    try:
        # First clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")

        # Create test data
        now = get_now_with_timezone()
        created_memcells = []

        for i in range(5):
            memcell = MemCell(
                user_id=user_id,
                timestamp=now - timedelta(hours=i),
                summary=f"Test memory {i+1}",
                episode=f"This is the detailed content of test memory {i+1}",
                type=DataTypeEnum.CONVERSATION,
                keywords=[f"keyword{i+1}", "test"],
            )
            created = await repo.append_memcell(memcell)
            created_memcells.append(created)

        logger.info("âœ… Created 5 test records")

        # Prepare event_ids
        event_ids = [str(mc.event_id) for mc in created_memcells[:3]]
        logger.info("   Preparing to query event_ids: %s", event_ids)

        # Test 1: Batch query (without projection)
        results = await repo.get_by_event_ids(event_ids)
        assert isinstance(results, dict), "Return result should be a dictionary"
        assert len(results) == 3, f"Should return 3 records, got {len(results)}"

        # Verify returned is a dictionary, key is event_id
        for event_id in event_ids:
            assert event_id in results, f"event_id {event_id} should be in results"
            memcell = results[event_id]
            assert memcell.user_id == user_id
            assert memcell.episode is not None

        logger.info("âœ… Test batch query (without projection) succeeded, returned %d records", len(results))

        # Test 2: Batch query (with field projection)
        # Use Pydantic projection model to return only specified fields, excluding large fields like original_data
        results_with_projection = await repo.get_by_event_ids(
            event_ids, projection_model=MemCellProjection
        )

        assert isinstance(results_with_projection, dict), "Return result should be a dictionary"
        assert (
            len(results_with_projection) == 3
        ), f"Should return 3 records, got {len(results_with_projection)}"

        # Verify projection effect: returned should be MemCellProjection instances
        for event_id, memcell_projection in results_with_projection.items():
            assert isinstance(
                memcell_projection, MemCellProjection
            ), "Returned should be MemCellProjection instance"
            assert memcell_projection.summary is not None, "summary field should exist"
            assert memcell_projection.timestamp is not None, "timestamp field should exist"
            assert memcell_projection.type is not None, "type field should exist"
            assert memcell_projection.user_id == user_id, "user_id should match"
            # Verify fields not defined in projection model are not included
            assert not hasattr(
                memcell_projection, 'original_data'
            ), "original_data field should not exist"
            assert not hasattr(memcell_projection, 'episode'), "episode field should not exist"

        logger.info(
            "âœ… Test batch query (with field projection) succeeded, returned %d records",
            len(results_with_projection),
        )

        # Test 3: Query partially valid event_ids (including an invalid one)
        mixed_event_ids = event_ids[:2] + ["invalid_id_123", "507f1f77bcf86cd799439011"]
        results_mixed = await repo.get_by_event_ids(mixed_event_ids)

        # Should only return 2 valid records
        assert (
            len(results_mixed) == 2
        ), f"Should return 2 records, got {len(results_mixed)}"
        assert event_ids[0] in results_mixed
        assert event_ids[1] in results_mixed
        assert "invalid_id_123" not in results_mixed
        assert "507f1f77bcf86cd799439011" not in results_mixed

        logger.info(
            "âœ… Test querying partially valid event_ids succeeded, returned %d records", len(results_mixed)
        )

        # Test 4: Empty list input
        results_empty = await repo.get_by_event_ids([])
        assert isinstance(results_empty, dict), "Return result should be a dictionary"
        assert len(results_empty) == 0, "Empty list should return empty dictionary"
        logger.info("âœ… Test empty list input succeeded")

        # Test 5: Query non-existent event_ids
        non_existent_ids = ["507f1f77bcf86cd799439011", "507f1f77bcf86cd799439012"]
        results_non_existent = await repo.get_by_event_ids(non_existent_ids)
        assert isinstance(results_non_existent, dict), "Return result should be a dictionary"
        assert len(results_non_existent) == 0, "Non-existent event_ids should return empty dictionary"
        logger.info("âœ… Test querying non-existent event_ids succeeded")

        # Test 6: Verify returned data integrity
        first_event_id = event_ids[0]
        first_memcell = results[first_event_id]
        original_memcell = created_memcells[0]

        assert str(first_memcell.event_id) == str(original_memcell.event_id)
        assert first_memcell.summary == original_memcell.summary
        assert first_memcell.user_id == original_memcell.user_id
        logger.info("âœ… Verified returned data integrity succeeded")

        # Clean up (using hard delete to clean up test data)
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up test data successfully")

    except Exception as e:
        logger.error("âŒ Test batch query by event_ids failed: %s", e)
        import traceback

        logger.error("Detailed error: %s", traceback.format_exc())
        raise

    logger.info("âœ… Batch query by event_ids test completed")


async def test_soft_delete_single():
    """æµ‹è¯•å•ä¸ªè½¯åˆ é™¤åŠŸèƒ½"""
    logger.info("Starting test of soft delete single record...")
    
    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_soft_delete_001"
    
    try:
        # æ¸…ç†æ—§æ•°æ®
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        now = get_now_with_timezone()
        memcell = MemCell(
            user_id=user_id,
            timestamp=now,
            summary="æµ‹è¯•è½¯åˆ é™¤çš„è®°å½•",
            type=DataTypeEnum.CONVERSATION,
        )
        created = await repo.append_memcell(memcell)
        event_id = str(created.event_id)
        logger.info("âœ… Created test record, event_id=%s", event_id)
        
        # éªŒè¯å¯ä»¥æŸ¥åˆ°
        found = await repo.get_by_event_id(event_id)
        assert found is not None, "Should be able to find the record"
        assert not found.is_deleted(), "Record should not be marked as deleted"
        logger.info("âœ… Verified: Can query the record before deletion")
        
        # æ‰§è¡Œè½¯åˆ é™¤
        deleted = await repo.delete_by_event_id(event_id, deleted_by="test_admin")
        assert deleted is True, "Soft delete should succeed"
        logger.info("âœ… Soft delete succeeded")
        
        # éªŒè¯å¸¸è§„æŸ¥è¯¢æ‰¾ä¸åˆ°
        not_found = await repo.get_by_event_id(event_id)
        assert not_found is None, "Regular query should not find soft-deleted record"
        logger.info("âœ… Verified: Regular query cannot find soft-deleted record")
        
        # ä½¿ç”¨ hard_find_one å¯ä»¥æ‰¾åˆ°
        hard_found = await MemCell.hard_find_one({"_id": created.id})
        assert hard_found is not None, "hard_find_one should find deleted record"
        assert hard_found.is_deleted(), "Record should be marked as deleted"
        assert hard_found.deleted_by == "test_admin", "Should record who deleted it"
        assert hard_found.deleted_at is not None, "Should have deletion timestamp"
        assert hard_found.deleted_id != 0, "deleted_id should be set"
        logger.info("âœ… Verified: hard_find_one can find deleted record")
        logger.info("   - deleted_by: %s", hard_found.deleted_by)
        logger.info("   - deleted_at: %s", hard_found.deleted_at)
        logger.info("   - deleted_id: %s", hard_found.deleted_id)
        
        # æ¢å¤è®°å½•
        restored = await repo.restore_by_event_id(event_id)
        assert restored is True, "Restore should succeed"
        logger.info("âœ… Restore succeeded")
        
        # éªŒè¯æ¢å¤åå¯ä»¥æŸ¥åˆ°
        restored_memcell = await repo.get_by_event_id(event_id)
        assert restored_memcell is not None, "Should find record after restore"
        assert not restored_memcell.is_deleted(), "Should not be marked as deleted after restore"
        assert restored_memcell.deleted_at is None, "deleted_at should be cleared"
        assert restored_memcell.deleted_by is None, "deleted_by should be cleared"
        assert restored_memcell.deleted_id == 0, "deleted_id should be reset to 0"
        logger.info("âœ… Verified: Record is normal after restore")
        
        # æ¸…ç†
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Test completed, cleaned up test data")
        
    except Exception as e:
        logger.error("âŒ Soft delete single test failed: %s", e)
        import traceback
        logger.error(traceback.format_exc())
        raise
    
    logger.info("âœ… Soft delete single test completed")


async def test_soft_delete_batch():
    """æµ‹è¯•æ‰¹é‡è½¯åˆ é™¤åŠŸèƒ½"""
    logger.info("Starting test of soft delete batch...")
    
    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_soft_delete_002"
    
    try:
        # æ¸…ç†æ—§æ•°æ®
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")
        
        # åˆ›å»º5æ¡æµ‹è¯•æ•°æ®
        now = get_now_with_timezone()
        for i in range(5):
            memcell = MemCell(
                user_id=user_id,
                timestamp=now - timedelta(hours=i),
                summary=f"æµ‹è¯•è®°å½• {i+1}",
                type=DataTypeEnum.CONVERSATION,
            )
            await repo.append_memcell(memcell)
        logger.info("âœ… Created 5 test records")
        
        # éªŒè¯å¯ä»¥æŸ¥åˆ°5æ¡
        results = await repo.find_by_user_id(user_id)
        assert len(results) == 5, f"Should have 5 records, got {len(results)}"
        logger.info("âœ… Verified: Can query 5 records")
        
        # æ‰¹é‡è½¯åˆ é™¤
        deleted_count = await repo.delete_by_user_id(user_id, deleted_by="batch_admin")
        assert deleted_count == 5, f"Should soft delete 5 records, got {deleted_count}"
        logger.info("âœ… Batch soft delete succeeded, deleted %d records", deleted_count)
        
        # éªŒè¯å¸¸è§„æŸ¥è¯¢æ‰¾ä¸åˆ°
        results_after_delete = await repo.find_by_user_id(user_id)
        assert len(results_after_delete) == 0, "Regular query should not find soft-deleted records"
        logger.info("âœ… Verified: Regular query cannot find soft-deleted records")
        
        # ä½¿ç”¨ hard_find_many å¯ä»¥æ‰¾åˆ°
        hard_results = await MemCell.hard_find_many({"user_id": user_id}).to_list()
        assert len(hard_results) == 5, f"hard_find_many should find 5 records, got {len(hard_results)}"
        logger.info("âœ… Verified: hard_find_many can find 5 deleted records")
        
        # éªŒè¯æ‰€æœ‰è®°å½•éƒ½è¢«æ ‡è®°ä¸ºå·²åˆ é™¤
        for mc in hard_results:
            assert mc.is_deleted(), "All records should be marked as deleted"
            assert mc.deleted_at is not None, "Should have deletion timestamp"
        logger.info("âœ… Verified: All records are correctly marked as deleted")
        
        # æ‰¹é‡æ¢å¤
        restored_count = await repo.restore_by_user_id(user_id)
        assert restored_count == 5, f"Should restore 5 records, got {restored_count}"
        logger.info("âœ… Batch restore succeeded, restored %d records", restored_count)
        
        # éªŒè¯æ¢å¤åå¯ä»¥æŸ¥åˆ°
        results_after_restore = await repo.find_by_user_id(user_id)
        assert len(results_after_restore) == 5, f"Should have 5 records after restore, got {len(results_after_restore)}"
        logger.info("âœ… Verified: Can query 5 records after restore")
        
        # æ¸…ç†
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Test completed, cleaned up test data")
        
    except Exception as e:
        logger.error("âŒ Soft delete batch test failed: %s", e)
        import traceback
        logger.error(traceback.format_exc())
        raise
    
    logger.info("âœ… Soft delete batch test completed")


async def test_hard_delete():
    """æµ‹è¯•ç¡¬åˆ é™¤åŠŸèƒ½"""
    logger.info("Starting test of hard delete...")
    
    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_hard_delete_001"
    
    try:
        # æ¸…ç†æ—§æ•°æ®
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        now = get_now_with_timezone()
        memcell = MemCell(
            user_id=user_id,
            timestamp=now,
            summary="æµ‹è¯•ç¡¬åˆ é™¤çš„è®°å½•",
            type=DataTypeEnum.CONVERSATION,
        )
        created = await repo.append_memcell(memcell)
        event_id = str(created.event_id)
        logger.info("âœ… Created test record, event_id=%s", event_id)
        
        # æ‰§è¡Œç¡¬åˆ é™¤
        deleted = await repo.hard_delete_by_event_id(event_id)
        assert deleted is True, "Hard delete should succeed"
        logger.info("âœ… Hard delete succeeded")
        
        # éªŒè¯ hard_find_one ä¹Ÿæ‰¾ä¸åˆ°ï¼ˆè®°å½•è¢«ç‰©ç†åˆ é™¤ï¼‰
        hard_found = await MemCell.hard_find_one({"_id": created.id})
        assert hard_found is None, "hard_find_one should not find hard-deleted record"
        logger.info("âœ… Verified: Record is completely removed after hard delete")
        
        logger.info("âœ… Test completed")
        
    except Exception as e:
        logger.error("âŒ Hard delete test failed: %s", e)
        import traceback
        logger.error(traceback.format_exc())
        raise
    
    logger.info("âœ… Hard delete test completed")


async def test_query_with_soft_delete_filtering():
    """æµ‹è¯•æŸ¥è¯¢è‡ªåŠ¨è¿‡æ»¤è½¯åˆ é™¤è®°å½•"""
    logger.info("Starting test of query filtering with soft delete...")
    
    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_query_filter_001"
    
    try:
        # æ¸…ç†æ—§æ•°æ®
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")
        
        # åˆ›å»º10æ¡è®°å½•
        now = get_now_with_timezone()
        event_ids = []
        for i in range(10):
            memcell = MemCell(
                user_id=user_id,
                timestamp=now - timedelta(hours=i),
                summary=f"æµ‹è¯•è®°å½• {i+1}",
                type=DataTypeEnum.CONVERSATION,
            )
            created = await repo.append_memcell(memcell)
            event_ids.append(str(created.event_id))
        logger.info("âœ… Created 10 test records")
        
        # è½¯åˆ é™¤å‰5æ¡
        for i in range(5):
            await repo.delete_by_event_id(event_ids[i], deleted_by="filter_test")
        logger.info("âœ… Soft deleted first 5 records")
        
        # æµ‹è¯• find_by_user_idï¼ˆåº”è¯¥åªè¿”å›5æ¡æœªåˆ é™¤çš„ï¼‰
        results = await repo.find_by_user_id(user_id)
        assert len(results) == 5, f"find_by_user_id should return 5, got {len(results)}"
        logger.info("âœ… Verified: find_by_user_id returns only 5 non-deleted records")
        
        # æµ‹è¯• count_by_user_idï¼ˆåº”è¯¥åªè®¡æ•°æœªåˆ é™¤çš„ï¼‰
        count = await repo.count_by_user_id(user_id)
        assert count == 5, f"count_by_user_id should return 5, got {count}"
        logger.info("âœ… Verified: count_by_user_id counts only non-deleted records")
        
        # ä½¿ç”¨ hard_find_many åº”è¯¥èƒ½æ‰¾åˆ°æ‰€æœ‰10æ¡
        all_results = await MemCell.hard_find_many({"user_id": user_id}).to_list()
        assert len(all_results) == 10, f"hard_find_many should return 10, got {len(all_results)}"
        logger.info("âœ… Verified: hard_find_many returns all 10 records including deleted")
        
        # ç»Ÿè®¡å·²åˆ é™¤å’Œæœªåˆ é™¤çš„æ•°é‡
        deleted_count = sum(1 for mc in all_results if mc.is_deleted())
        active_count = sum(1 for mc in all_results if not mc.is_deleted())
        assert deleted_count == 5, f"Should have 5 deleted, got {deleted_count}"
        assert active_count == 5, f"Should have 5 active, got {active_count}"
        logger.info("âœ… Verified: %d deleted, %d active", deleted_count, active_count)
        
        # æ¸…ç†
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Test completed, cleaned up test data")
        
    except Exception as e:
        logger.error("âŒ Query filtering test failed: %s", e)
        import traceback
        logger.error(traceback.format_exc())
        raise
    
    logger.info("âœ… Query filtering test completed")


async def test_prevent_duplicate_soft_delete():
    """æµ‹è¯•é˜²æ­¢é‡å¤è½¯åˆ é™¤ï¼ˆä¿æŠ¤å®¡è®¡è®°å½•ï¼‰"""
    logger.info("Starting test of preventing duplicate soft delete...")
    
    repo = get_bean_by_type(MemCellRawRepository)
    user_id = "test_user_duplicate_delete_001"
    
    try:
        # æ¸…ç†æ—§æ•°æ®
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Cleaned up existing test data")
        
        # åˆ›å»º5æ¡æµ‹è¯•è®°å½•
        now = get_now_with_timezone()
        event_ids = []
        for i in range(5):
            memcell = MemCell(
                user_id=user_id,
                timestamp=now - timedelta(hours=i),
                summary=f"æµ‹è¯•è®°å½• {i+1}",
                type=DataTypeEnum.CONVERSATION,
            )
            created = await repo.append_memcell(memcell)
            event_ids.append(str(created.event_id))
        logger.info("âœ… Created 5 test records")
        
        # ç¬¬ä¸€æ¬¡è½¯åˆ é™¤å‰3æ¡è®°å½•
        first_delete_time = get_now_with_timezone()
        for i in range(3):
            await repo.delete_by_event_id(event_ids[i], deleted_by="admin_1")
        logger.info("âœ… First soft delete of 3 records by admin_1")
        
        # è·å–å·²åˆ é™¤è®°å½•çš„å®¡è®¡ä¿¡æ¯
        deleted_records = []
        for i in range(3):
            mc = await MemCell.hard_find_one({"_id": ObjectId(event_ids[i])})
            assert mc is not None
            assert mc.is_deleted()
            deleted_records.append({
                "event_id": event_ids[i],
                "deleted_at": mc.deleted_at,
                "deleted_by": mc.deleted_by,
                "deleted_id": mc.deleted_id,
            })
        logger.info("âœ… Captured audit info from first delete")
        
        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿æ—¶é—´æˆ³ä¼šä¸åŒ
        from asyncio import sleep
        await sleep(0.01)
        
        # å°è¯•å†æ¬¡è½¯åˆ é™¤åŒæ ·çš„è®°å½•ï¼ˆåº”è¯¥è¢«å¿½ç•¥ï¼‰
        result = await repo.delete_by_user_id(user_id, deleted_by="admin_2")
        # æ³¨æ„ï¼šdelete_by_user_id ä¼šå°è¯•åˆ é™¤æ‰€æœ‰è®°å½•ï¼Œä½†åªæœ‰æœªåˆ é™¤çš„ä¼šè¢«ä¿®æ”¹
        # å‰3æ¡å·²åˆ é™¤ï¼Œå2æ¡æœªåˆ é™¤ï¼Œæ‰€ä»¥åº”è¯¥åªä¿®æ”¹2æ¡
        assert result == 2, f"Should only soft delete 2 un-deleted records, got {result}"
        logger.info("âœ… Second delete only affected 2 un-deleted records")
        
        # éªŒè¯å‰3æ¡è®°å½•çš„å®¡è®¡ä¿¡æ¯æ²¡æœ‰è¢«ä¿®æ”¹
        for i, original in enumerate(deleted_records):
            mc = await MemCell.hard_find_one({"_id": ObjectId(original["event_id"])})
            assert mc is not None
            assert mc.is_deleted()
            assert mc.deleted_at == original["deleted_at"], \
                f"deleted_at should not change for record {i}"
            assert mc.deleted_by == original["deleted_by"], \
                f"deleted_by should not change for record {i}, expected {original['deleted_by']}, got {mc.deleted_by}"
            assert mc.deleted_id == original["deleted_id"], \
                f"deleted_id should not change for record {i}"
        logger.info("âœ… Verified: First 3 records' audit info was NOT modified")
        
        # éªŒè¯å2æ¡è®°å½•è¢«æ–°çš„åˆ é™¤æ“ä½œæ ‡è®°
        for i in range(3, 5):
            mc = await MemCell.hard_find_one({"_id": ObjectId(event_ids[i])})
            assert mc is not None
            assert mc.is_deleted()
            # è¿™ä¸¤æ¡åº”è¯¥è¢«æ–°åˆ é™¤æ“ä½œæ ‡è®°
            assert mc.deleted_at > first_delete_time, "Should have newer deletion time"
            # æ³¨æ„ï¼šç”±äºæ˜¯æ‰¹é‡åˆ é™¤ï¼Œdeleted_by å¯èƒ½æ˜¯ admin_2
        logger.info("âœ… Verified: Last 2 records were soft deleted by second operation")
        
        # æµ‹è¯•å•ä¸ªæ–‡æ¡£çš„é‡å¤åˆ é™¤ä¿æŠ¤
        test_record = await MemCell.hard_find_one({"_id": ObjectId(event_ids[0])})
        original_deleted_at = test_record.deleted_at
        original_deleted_by = test_record.deleted_by
        original_deleted_id = test_record.deleted_id
        
        # å†æ¬¡å°è¯•åˆ é™¤ï¼ˆåº”è¯¥è¢«å¿½ç•¥ï¼‰
        await test_record.delete(deleted_by="admin_3")
        
        # é‡æ–°è·å–è®°å½•
        test_record_after = await MemCell.hard_find_one({"_id": ObjectId(event_ids[0])})
        assert test_record_after.deleted_at == original_deleted_at, \
            "deleted_at should not change on duplicate delete"
        assert test_record_after.deleted_by == original_deleted_by, \
            "deleted_by should not change on duplicate delete"
        assert test_record_after.deleted_id == original_deleted_id, \
            "deleted_id should not change on duplicate delete"
        logger.info("âœ… Verified: Instance method delete() also prevents duplicate deletion")
        
        # æ¸…ç†
        await repo.hard_delete_by_user_id(user_id)
        logger.info("âœ… Test completed, cleaned up test data")
        
    except Exception as e:
        logger.error("âŒ Prevent duplicate soft delete test failed: %s", e)
        import traceback
        logger.error(traceback.format_exc())
        raise
    
    logger.info("âœ… Prevent duplicate soft delete test completed")


async def run_all_tests():
    """Run all tests"""
    logger.info("ğŸš€ Starting to run all MemCellRawRepository tests...")

    try:
        await test_basic_crud_operations()
        await test_find_by_user_id()
        await test_find_by_time_range()
        await test_find_by_user_and_time_range()
        await test_find_by_group_id()
        await test_find_by_participants()
        await test_search_by_keywords()
        await test_batch_delete_operations()
        await test_statistics_and_aggregation()
        await test_get_by_event_ids()
        
        # è½¯åˆ é™¤åŠŸèƒ½æµ‹è¯•
        logger.info("")
        logger.info("=" * 60)
        logger.info("Starting Soft Delete Feature Tests...")
        logger.info("=" * 60)
        await test_soft_delete_single()
        await test_soft_delete_batch()
        await test_hard_delete()
        await test_query_with_soft_delete_filtering()
        await test_prevent_duplicate_soft_delete()
        
        logger.info("")
        logger.info("=" * 60)
        logger.info("âœ…âœ…âœ… All tests completed!")
        logger.info("=" * 60)
        logger.info("")
        logger.info("è½¯åˆ é™¤åŠŸèƒ½éªŒè¯æ€»ç»“ï¼š")
        logger.info("1. âœ… å•ä¸ªè½¯åˆ é™¤æ­£å¸¸å·¥ä½œ")
        logger.info("2. âœ… æ‰¹é‡è½¯åˆ é™¤æ­£å¸¸å·¥ä½œ")
        logger.info("3. âœ… æ¢å¤åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        logger.info("4. âœ… æŸ¥è¯¢è‡ªåŠ¨è¿‡æ»¤å·²åˆ é™¤è®°å½•")
        logger.info("5. âœ… hard_find å¯ä»¥æŸ¥è¯¢å·²åˆ é™¤è®°å½•")
        logger.info("6. âœ… ç¡¬åˆ é™¤ï¼ˆç‰©ç†åˆ é™¤ï¼‰æ­£å¸¸å·¥ä½œ")
        logger.info("7. âœ… deleted_byã€deleted_atã€deleted_id å­—æ®µæ­£ç¡®è®¾ç½®")
        logger.info("8. âœ… é˜²æ­¢é‡å¤è½¯åˆ é™¤ï¼Œä¿æŠ¤å®¡è®¡è®°å½•")
    except Exception as e:
        logger.error("âŒ Error occurred during testing: %s", e)
        raise


if __name__ == "__main__":
    asyncio.run(run_all_tests())